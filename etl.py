8import json
import os
from typing import Counter
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
import logging
from datetime import datetime
import numpy as np
import time

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
import re
import unicodedata

# CONFIGURA√á√ÉO DO LOGGER
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = logging.getLogger("ETL")


# CARREGA CREDENCIAIS DO GOOGLE SHEETS DAS VARI√ÅVEIS DE AMBIENTE
def load_google_credentials():
    json_path = os.environ.get("GOOGLE_CREDENTIALS_JSON")
    if not json_path:
        raise ValueError("Vari√°vel GOOGLE_CREDENTIALS_JSON n√£o definida.")

    scopes = [
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive"
    ]

    return Credentials.from_service_account_file(json_path, scopes=scopes)


# EXTRACT ‚Äì LE O GOOGLE SHEETS
def extract(sheet_id: str, tab_name: str):
    logger.info(f"Lendo planilha: {sheet_id} | Aba: {tab_name}")

    creds = load_google_credentials()
    client = gspread.authorize(creds)

    ws = client.open_by_key(sheet_id).worksheet(tab_name)

    # Mais r√°pido que get_all_records
    values = ws.get_all_values()
    df = pd.DataFrame(values[1:], columns=values[0])

    logger.info(f"Linhas carregadas: {len(df)}")
    return df, client

def limpar_texto(texto: str) -> str:
    texto = unicodedata.normalize('NFKD', texto).encode('ascii', 'ignore').decode('utf-8')
    texto = re.sub(r'[^a-zA-Z\s]', ' ', texto.lower())
    texto = re.sub(r'\s+', ' ', texto).strip()
    return texto

def gerar_nome_grupo(textos: list[str]) -> str:
    """
    Gera um nome leg√≠vel para o grupo com base nas palavras mais comuns
    """
    # Palavras-chave conhecidas (voc√™ pode expandir)
    palavras_chave = {
        'admin': 'Administrativo',
        'vigilancia': 'Vigil√¢ncia Epidemiol√≥gica',
        'viep': 'Vigil√¢ncia Epidemiol√≥gica',
        'visa': 'Vigil√¢ncia Sanit√°ria',
        'enferm': 'Enfermagem',
        'chef': 'Chefia',
        'acao': 'A√ß√µes e Servi√ßos',
        'dent': 'Sa√∫de Bucal',
        'odont': 'Sa√∫de Bucal',
        'farm': 'Farm√°cia',
        'ti': 'TI/Suporte',
        'inform': 'TI/Suporte',
        'nutri': 'Nutri√ß√£o',
        'imun': 'Imuniza√ß√£o',
        'saude mulh': 'Sa√∫de da Mulher',
        'saude crianc': 'Sa√∫de da Crian√ßa',
        'adolescent': 'Sa√∫de do Adolescente',
        'epidem': 'Epidemiologia',
        'nuget': 'Epidemiologia',
        'sanitar': 'Sanitarista',
        'serv geral': 'Servi√ßos Gerais',
        'motorist': 'Servi√ßos Gerais',
        'rh': 'RH',
        'pessoal': 'RH',
        'tecnico': 'T√©cnico',
        'referencia': 'Refer√™ncia T√©cnica',
        'curativ': 'Curativos',
        'tubercul': 'Tuberculose',
        'sala imun': 'Imuniza√ß√£o',
        'vacin': 'Imuniza√ß√£o',
        'ouvid': 'Ouvidoria',
        'diret': 'Diretoria',
        'subcoord': 'Subcoordenadoria',
        'coord': 'Coordena√ß√£o'
    }

    # Contar palavras limpas
    texto_unido = ' '.join([limpar_texto(t) for t in textos])
    palavras = texto_unido.split()
    contador = Counter(palavras)

    # Detectar palavra-chave mais frequente
    for palavra, nome in palavras_chave.items():
        if contador[palavra] > 0:
            return nome

    # Se n√£o encontrou, usar as 2 palavras mais frequentes
    top = contador.most_common(2)
    if len(top) >= 2:
        return f"{top[0][0].capitalize()} / {top[1][0].capitalize()}"
    elif len(top) == 1:
        return f"{top[0][0].capitalize()}"
    else:
        return "Outros"
    
def normalizar_area_atuacao(df: pd.DataFrame, n_clusters: int = 15) -> pd.DataFrame:
    df = df.copy()
    df['area_limpa'] = df['area_atuacao'].fillna('').apply(limpar_texto)

    vetorizador = TfidfVectorizer(max_features=500, stop_words='english')
    X = vetorizador.fit_transform(df['area_limpa'])

    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    df['grupo'] = kmeans.fit_predict(X)

    grupo_nome = {}
    for grupo in df['grupo'].unique():
        textos_originais = df[df['grupo'] == grupo]['area_atuacao'].tolist()
        nome = gerar_nome_grupo(textos_originais)
        grupo_nome[grupo] = nome

    df['area_atuacao_normalizada'] = df['grupo'].map(grupo_nome)

    print("üìä Grupos detectados:")
    for grupo, nome in grupo_nome.items():
        amostra = df[df['grupo'] == grupo]['area_atuacao'].mode()[0] if not df[df['grupo'] == grupo]['area_atuacao'].mode().empty else "-"
        print(f"  Grupo {grupo}: {nome} (ex: '{amostra}')")

    df['area_atuacao'] = df['area_atuacao_normalizada']
    df = df.drop(columns=['area_limpa', 'grupo', 'area_atuacao_normalizada'])

    return df

def rename_columns(df: pd.DataFrame) -> pd.DataFrame:
    """
    Renomeia as colunas do DataFrame conforme o mapeamento fornecido.
    """
    rename_map = {
        "Carimbo de data/hora": "timestamp",
        "1 - Distrito Sanit√°rio (DS) ao qual voc√™ est√° vinculado": "ds_vinculado",
        "2 - Voc√™ √© coordenador do DS?": "coord_ds",
        "3  - Se n√£o, qual a sua √°rea de atua√ß√£o no DS?": "area_atuacao",
        "4 - Na sua √°rea de atua√ß√£o, voc√™ trabalha diretamente com a coleta, an√°lise ou gest√£o da informa√ß√£o?": "atuacao_info",
        "6 - Voc√™ participa de qualifica√ß√µes sobre an√°lise de dados, sistemas de informa√ß√£o ou planejamento em sa√∫de?": "participa_qualificacoes",
        "7 - Na sua opini√£o existe,  por parte dos profissionais, uma cultura de valoriza√ß√£o e uso de dados para a tomada de decis√£o no dia a dia do Distrito Sanit√°rio?": "cultura_uso_dados",
        "8 - Quais ferramentas s√£o mais utilizadas por voc√™ para analisar dados?": "ferramentas_analise",
        "9 - O distrito sanit√°rio de sa√∫de possui esta√ß√µes de trabalho (computador, teclado, mouse e monitor) em condi√ß√µes adequadas de uso? Quantas? ": "estacoes_trabalho_boas",
        "10 - Quantos computadores de mesa est√£o instalados, mas apresentam problemas recorrentes (lentid√£o, defeitos de hardware, etc.)?": "computadores_problema",
        "11 - O Distrito Sanit√°rio possui notebooks em condi√ß√µes de uso? Se sim, quantos?": "notebooks_boas",
        "11.1 - Se respondeu sim na pergunta anterior, quantos desses notebooks possuem c√¢mera, microfone e alto-falantes integrados e funcionais?  [C√¢meras (webcams)]": "notebooks_com_camera",
        "11.1 - Se respondeu sim na pergunta anterior, quantos desses notebooks possuem c√¢mera, microfone e alto-falantes integrados e funcionais?  [Caixas de som]": "notebooks_com_caixa_som",
        "11.1 - Se respondeu sim na pergunta anterior, quantos desses notebooks possuem c√¢mera, microfone e alto-falantes integrados e funcionais?  [Microfones]": "notebooks_com_microfone",
        "12 - Para realizar reuni√µes remotas (videoconfer√™ncias), marque quantos dos seguintes itens est√£o dispon√≠veis e em condi√ß√£o de uso no Distrito Sanit√°rio: [C√¢meras (webcams)]": "webcams_disponiveis",
        "12 - Para realizar reuni√µes remotas (videoconfer√™ncias), marque quantos dos seguintes itens est√£o dispon√≠veis e em condi√ß√£o de uso no Distrito Sanit√°rio: [Microfones (de mesa ou headsets):]": "microfones_disponiveis",
        "12 - Para realizar reuni√µes remotas (videoconfer√™ncias), marque quantos dos seguintes itens est√£o dispon√≠veis e em condi√ß√£o de uso no Distrito Sanit√°rio: [Fones de ouvido (headsets ou simples):]": "fones_disponiveis",
        "12 - Para realizar reuni√µes remotas (videoconfer√™ncias), marque quantos dos seguintes itens est√£o dispon√≠veis e em condi√ß√£o de uso no Distrito Sanit√°rio: [Caixas de som (para uso coletivo em sala):]": "caixas_som_disponiveis",
        "13 - O Distrito Sanit√°rio possui televisores ou projetores que podem ser conectados a computadores/notebooks para apresenta√ß√µes? Se sim, quantos?  [Televisor]": "televisores",
        "14 - Existem cabos (ex: HDMI) ou adaptadores dispon√≠veis e funcionais para conectar os computadores a esses televisores/projetores?": "cabos_adaptadores",
        "15 - Nos √∫ltimos 6 meses, o Distrito Sanit√°rio possuiu conex√£o est√°vel com a internet, permitindo o uso de videoconfer√™ncias e acesso a sistemas de informa√ß√£o em sa√∫de online e pain√©is de BI?": "internet_estavel",
        "15.1 - Se sim, em uma escala de 0 (p√©ssima) a 10 (excelente), como voc√™ avalia a qualidade geral (velocidade e estabilidade) da internet?": "qualidade_internet",
        "16 - A rede de internet no Distrito Sanit√°rio √©:": "tipo_rede_internet",
        "17 - O acesso √† rede Wi-Fi, se existente, √©:": "acesso_wifi",
        "18 - A estrutura el√©trica do Distrito Sanit√°rio suporta a inser√ß√£o de novos equipamentos tecnol√≥gicos (Ex: mais computadores, televisores, etc.)?": "estrutura_eletrica_suporta",
        "19 - O Distrito Sanit√°rio possui uma sala adequada para a realiza√ß√£o de reuni√µes em grupo e que possa abrigar a estrutura da Sala de Situa√ß√£o (proje√ß√£o de pain√©is, computadores, etc.)?": "sala_situacao",
        "19.1 - Se possui uma sala, ela √© climatizada (com ar-condicionado em funcionamento)?": "sala_climatizada",
        "20 - H√° indicadores definidos para monitorar o desempenho das a√ß√µes de sa√∫de acompanhadas pela equipe t√©cnica distrital?": "indicadores_definidos",
        "21 - As informa√ß√µes e an√°lises de dados geradas no Distrito Sanit√°rio subsidiam a elabora√ß√£o das metas para a Programa√ß√£o Operativa Anual (POA)?": "dados_subsidiam_metas",
        "21.1 - Se sim na pergunta anterior, descreva brevemente quais s√£o os principais indicadores acompanhados.": "principais_indicadores",
        "22 - As metas distritais s√£o definidas a partir da an√°lise dos dados?": "metas_base_dados",
        "23 - Existem meios de comunica√ß√£o entre o Distrito Sanit√°rio e as √°reas t√©cnicas do N√≠vel Central para dialogar sobre os indicadores por territ√≥rio?": "comunicacao_nivel_central",
        "23.1 - Se sim, descreva quais os meios de comunica√ß√£o utilizados (e-mail, reuni√µes, of√≠cios, grupos de mensagens, etc.) e com quais √°reas t√©cnicas.": "meios_comunicacao",
        "24 - H√° periodicidade definida para atualiza√ß√£o e revis√£o das metas estrat√©gicas que comp√µem a POA do Distrito Sanit√°rio?": "periodicidade_revisao_metas",
        "24.1 - Se sim, qual a periodicidade?": "periodicidade_metas",
        "25 - Quais bases de dados dos Sistemas de Informa√ß√£o em Sa√∫de (SIS), elencados abaixo, voc√™ utiliza para tabula√ß√£o e an√°lise dos dados no Distrito Sanit√°rio?": "sistemas_informacao_utilizados",
        "26 - Apenas para os sistemas escolhidos na quest√£o anterior, avalie a qualidade dos dados desses sistemas refletindo em suas dimens√µes de qualidade. [SINASC]": "qualidade_sinasc",
        "26 - Apenas para os sistemas escolhidos na quest√£o anterior, avalie a qualidade dos dados desses sistemas refletindo em suas dimens√µes de qualidade. [Vida+]": "qualidade_vida_plus",
        "26 - Apenas para os sistemas escolhidos na quest√£o anterior, avalie a qualidade dos dados desses sistemas refletindo em suas dimens√µes de qualidade. [E-SUS AB/SISAB]": "qualidade_esus_sisab",
        "26 - Apenas para os sistemas escolhidos na quest√£o anterior, avalie a qualidade dos dados desses sistemas refletindo em suas dimens√µes de qualidade. [SINAN]": "qualidade_sinan",
        "26 - Apenas para os sistemas escolhidos na quest√£o anterior, avalie a qualidade dos dados desses sistemas refletindo em suas dimens√µes de qualidade. [GAL]": "qualidade_gal",
        "26 - Apenas para os sistemas escolhidos na quest√£o anterior, avalie a qualidade dos dados desses sistemas refletindo em suas dimens√µes de qualidade. [SIA-SUS]": "qualidade_sia_sus",
        "26 - Apenas para os sistemas escolhidos na quest√£o anterior, avalie a qualidade dos dados desses sistemas refletindo em suas dimens√µes de qualidade. [SIH-SUS]": "qualidade_sih_sus",
        "26 - Apenas para os sistemas escolhidos na quest√£o anterior, avalie a qualidade dos dados desses sistemas refletindo em suas dimens√µes de qualidade. [SIM]": "qualidade_sim",
        "26 - Apenas para os sistemas escolhidos na quest√£o anterior, avalie a qualidade dos dados desses sistemas refletindo em suas dimens√µes de qualidade. [Sivep-Gripe]": "qualidade_sivep_gripe",
        "26 - Apenas para os sistemas escolhidos na quest√£o anterior, avalie a qualidade dos dados desses sistemas refletindo em suas dimens√µes de qualidade. [E-SUS Notifica]": "qualidade_esus_notifica",
        "26 - Apenas para os sistemas escolhidos na quest√£o anterior, avalie a qualidade dos dados desses sistemas refletindo em suas dimens√µes de qualidade. [Sisvan]": "qualidade_sisvan",
        "27 - Em rela√ß√£o aos dados digitados no Distrito Sanit√°rio, os fluxos de coleta e digita√ß√£o est√£o formalizados com as unidades de sa√∫de do territ√≥rio? (Ex: Fichas do SINAN que s√£o oriundas de unidades hospitalares)": "fluxos_formalizados",
        "28 - Existe rotina de confer√™ncia e valida√ß√£o da consist√™ncia dos dados que s√£o digitados no Distrito Sanit√°rio?": "rotina_validacao",
        "29 - Na sua opini√£o, a equipe respons√°vel pelo registro dos dados √© devidamente treinada?": "equipe_treinada",
        "30 - Quais foram as a√ß√µes (planejamento, interven√ß√µes, etc.) realizadas a partir dos dados tabulados no Distrito Sanit√°rio?": "acoes_base_dados",
        "31 - Os resultados dos indicadores s√£o comparados com s√©ries hist√≥ricas ou padr√µes de refer√™ncia para an√°lise de tend√™ncias?": "comparacao_series_historicas",
        "32 - H√° momentos institucionais de devolutiva e discuss√µes dos resultados com as equipes das unidades de sa√∫de? ": "devolutiva_resultados",
        "33 - Os boletins, informes ou comunicados com resultados dos indicadores de sa√∫de analisados s√£o discutidos com as unidades de sa√∫de do territ√≥rio? ": "discussao_boletins",
        "34 - Os pain√©is da Sala de Situa√ß√£o est√£o sendo utilizados para a tomada de decis√£o? ": "paineis_tomada_decisao",
        "34.1 - Se sim, especificar quais pain√©is s√£o mais utilizados. ": "paineis_utilizados",
        "35 - Na sua opini√£o, existe est√≠mulo √† inova√ß√£o e ao uso de novas ferramentas digitais para an√°lise de dados no  Distrito Sanit√°rio?": "estimulo_inovacao",
        "36 - Voc√™ compreende o papel estrat√©gico da Sala de Situa√ß√£o como uma ferramenta de apoio √† gest√£o?": "compreensao_sala_situacao",
        "37 - O Distrito Sanit√°rio tem alguma unidade de sa√∫de que utiliza a telessa√∫de para a realiza√ß√£o de consultas ou atendimentos remotos? ": "telessaude",
        "38 - Voc√™ sabe o que √© e qual o objetivo da Lei Geral de Prote√ß√£o de Dados Pessoais (LGPD)?": "conhecimento_lgpd",
        "39 - Voc√™ j√° recebeu treinamentos ou orienta√ß√µes formais sobre a confidencialidade das informa√ß√µes de sa√∫de e a conformidade com a LGPD?": "treinamento_lgpd",
        "40 - O acesso aos sistemas de informa√ß√£o √© controlado por n√≠veis de permiss√£o individualizados (cada profissional com seu pr√≥prio login e senha)?": "acesso_individualizado",
        "41 - Existem protocolos de backup e recupera√ß√£o de dados para os sistemas que s√£o alimentados localmente no Distrito Sanit√°rio?": "protocolos_backup",
        "5 - Em uma escala de 1 (nenhuma) a 5 (muita), como voc√™ avalia a compet√™ncia t√©cnica da equipe do distrito para analisar e interpretar indicadores de sa√∫de? [.]": "competencia_tecnica_equipe",
        "13 - O Distrito Sanit√°rio possui televisores ou projetores que podem ser conectados a computadores/notebooks para apresenta√ß√µes? Se sim, quantos?  [Projetor]": "projetores"
    }

    df = df.rename(columns=rename_map)
    return df

def transformar_atuacao_info(df: pd.DataFrame) -> pd.DataFrame:
    """
    Transforma a coluna de m√∫ltipla escolha em colunas bin√°rias individuais
    """
    
    
    # Criar colunas bin√°rias para cada op√ß√£o
    df['atuacao_coleta'] = df['atuacao_info'].str.lower().str.strip().str.contains('coleta', na=False).astype(int)
    df['atuacao_analise'] = df['atuacao_info'].str.lower().str.strip().str.contains('an√°lise', na=False).astype(int)
    df['atuacao_gestao'] = df['atuacao_info'].str.lower().str.strip().str.contains('gest√£o', na=False).astype(int)
    df['atuacao_nao'] = (df['atuacao_info'].str.lower().str.strip() == 'n√£o').astype(int)
    
    # Debug: verificar se as colunas foram criadas
    '''
    print("Colunas criadas:")
    print(f"Coleta: {df['atuacao_coleta'].sum()}")
    print(f"An√°lise: {df['atuacao_analise'].sum()}")
    print(f"Gest√£o: {df['atuacao_gestao'].sum()}")
    print(f"N√£o: {df['atuacao_nao'].sum()}")
    '''
    
    # Agora criar as colunas combinadas
    df['atuacao_multipla'] = (df['atuacao_coleta'] + df['atuacao_analise'] + df['atuacao_gestao'] > 1).astype(int)
    df['atuacao_apenas_uma'] = (df['atuacao_coleta'] + df['atuacao_analise'] + df['atuacao_gestao'] == 1).astype(int)
    
    # Criar categorias combinadas
    conditions = [
        (df['atuacao_coleta'] == 1) & (df['atuacao_analise'] == 1) & (df['atuacao_gestao'] == 1),
        (df['atuacao_coleta'] == 1) & (df['atuacao_analise'] == 1),
        (df['atuacao_analise'] == 1) & (df['atuacao_gestao'] == 1),
        (df['atuacao_coleta'] == 1) & (df['atuacao_gestao'] == 1),
        (df['atuacao_coleta'] == 1),
        (df['atuacao_analise'] == 1),
        (df['atuacao_gestao'] == 1),
        (df['atuacao_nao'] == 1)
    ]
    
    choices = [
        'Coleta+An√°lise+Gest√£o',
        'Coleta+An√°lise',
        'An√°lise+Gest√£o',
        'Coleta+Gest√£o',
        'Apenas Coleta',
        'Apenas An√°lise',
        'Apenas Gest√£o',
        'Nenhuma'
    ]
    
    df['atuacao_categoria'] = np.select(conditions, choices, default='Outro')

    '''
    print("Distribui√ß√£o das categorias:")
    print(df['atuacao_categoria'].value_counts())
    '''
    return df

def transformar_ferramentas_analise(df: pd.DataFrame) -> pd.DataFrame:
    """
    Transforma a coluna de ferramentas de an√°lise em colunas bin√°rias
    """
    
    # Mapeamento b√°sico das ferramentas padr√£o
    mapeamento_ferramentas = {
        'Planilhas (Excel, Google Sheets, etc.)': 'Planilhas',
        'Sistemas de tabula√ß√£o do SUS (Tabwin, TabNet, etc.)': 'Sistemas SUS', 
        'Pain√©is de BI (Qlik Sense, Power BI, Looker Studio, Oracle, Sistema de Monitoramento da APS, etc.)': 'Pain√©is BI',
        'Apresenta√ß√µes (PowerPoint, Google Slides, etc.)': 'Apresenta√ß√µes',
    }
    
    def categorizar_ferramentas(texto):
        if pd.isna(texto) or texto == '':
            return set(['Outras Ferramentas'])
        
        texto = str(texto).strip().lower()
        categorias = set()
        
        # Verificar se √© "nenhuma ferramenta" ou similar
        if any(phrase in texto for phrase in ['nenhuma ferramenta', 'n√£o faz an√°lise', 'n√£o faz analise', 'incipiente', 'n√£o faz an√°lise']):
            return set(['Outras Ferramentas'])
        
        # 1. Primeiro busca pelos padr√µes exatos do mapeamento
        for padrao, categoria in mapeamento_ferramentas.items():
            if padrao.lower() in texto:
                categorias.add(categoria)
        
        # 2. Busca por palavras-chave para categorizar automaticamente
        palavras_chave = {
            'Planilhas': ['planilha', 'excel', 'google sheets', 'calc', 'sheet'],
            'Sistemas SUS': ['sistema', 'tabwin', 'tabnet', 'sus', 'sinan', 'siscan', 'sivep', 
                           'sisvan', 'sim', 'sinasc', 'gal', 'sia', 'sih', 'datasus', 'e-sus'],
            'Pain√©is BI': ['painel', 'bi', 'business intelligence', 'qlik', 'power bi', 'looker', 
                          'oracle', 'tableau', 'dashboard', 'pain√©is'],
            'Apresenta√ß√µes': ['apresenta√ß√£o', 'powerpoint', 'google slides', 'slide', 'ppt']
        }
        
        for categoria, palavras in palavras_chave.items():
            for palavra in palavras:
                if palavra in texto:
                    categorias.add(categoria)
                    break
        
        # Se n√£o encontrou nenhuma categoria padr√£o, classifica como "Outras Ferramentas"
        if len(categorias) == 0:
            categorias.add('Outras Ferramentas')
        
        return categorias
    
    # Criar colunas dummy para cada categoria
    categorias = ['Planilhas', 'Sistemas SUS', 'Pain√©is BI', 'Apresenta√ß√µes', 'Outras Ferramentas']
    
    for categoria in categorias:
        coluna_nome = f"ferramenta_{categoria.lower().replace(' ', '_').replace('√£', 'a').replace('√ß', 'c').replace('√©', 'e')}"
        df[coluna_nome] = df['ferramentas_analise'].apply(
            lambda x: 1 if categoria in categorizar_ferramentas(x) else 0
        )
    
    # Debug: mostrar distribui√ß√£o
    print("Distribui√ß√£o das ferramentas:")
    for categoria in categorias:
        coluna = f"ferramenta_{categoria.lower().replace(' ', '_').replace('√£', 'a').replace('√ß', 'c').replace('√©', 'e')}"
        print(f"{categoria}: {df[coluna].sum()}")
    
    # Calcular quantidade de ferramentas usadas (excluindo "Outras Ferramentas")
    colunas_ferramentas_principais = [f"ferramenta_{cat.lower().replace(' ', '_').replace('√£', 'a').replace('√ß', 'c').replace('√©', 'e')}" 
                                     for cat in ['Planilhas', 'Sistemas SUS', 'Pain√©is BI', 'Apresenta√ß√µes']]
    
    df['qtd_ferramentas'] = df[colunas_ferramentas_principais].sum(axis=1)
    
    # Categorizar por quantidade
    conditions = [
        df['qtd_ferramentas'] == 0,
        df['qtd_ferramentas'] == 1,
        df['qtd_ferramentas'] == 2,
        df['qtd_ferramentas'] >= 3
    ]
    
    choices = ['Nenhuma', '1 ferramenta', '2 ferramentas', '3+ ferramentas']
    
    df['categoria_ferramentas'] = np.select(conditions, choices, default='Nenhuma')
    
    '''
    print(f"\nPessoas sem ferramentas principais: {(df['qtd_ferramentas'] == 0).sum()}")
    print(f"Pessoas com 1 ferramenta principal: {(df['qtd_ferramentas'] == 1).sum()}")
    print(f"Pessoas com 2 ferramentas principais: {(df['qtd_ferramentas'] == 2).sum()}")
    print(f"Pessoas com 3+ ferramentas principais: {(df['qtd_ferramentas'] >= 3).sum()}")
    print(f"Pessoas com outras ferramentas: {df['ferramenta_outras_ferramentas'].sum()}")
    '''

    return df

def transformar_categoricos_grandes(df: pd.DataFrame) -> pd.DataFrame:
    """
    Transforma as colunas em valores num√©ricos e categorias ordenados
    """
    
    # Mapeamento para valores num√©ricos (ponto m√©dio dos intervalos)
    mapeamento_numerico = {
        '1 a 10': 5,
        '11 a 15': 13, 
        '16 a 20': 18,
        '21 ou mais': 25,
        'Nenhum': 0,
        'N√£o sei informar': None,
        '': None
    }
    
    
    # Aplicar mapeamento √†s colunas espec√≠ficas
    colunas_perifericos = [
        'estacoes_trabalho_boas'
    
    ]

    
    for coluna in colunas_perifericos:
        if coluna not in df.columns:
            continue
            
        # 1. Criar vers√£o num√©rica
        df[f'{coluna}_num'] = df[coluna].map(mapeamento_numerico)
        
        # 2. Substituir a coluna original pela vers√£o ordenada
        ordem_categorias = ['Nenhum', '1 a 10', '11 a 15', '16 a 20', '21 ou mais']
        df[coluna] = pd.Categorical(
            df[coluna], 
            categories=ordem_categorias, 
            ordered=True
        )
        
        # 3. Criar categorias simplificadas
        conditions = [
            df[coluna].isin(['1 a 10', 'Nenhum']),
            df[coluna] == '11 a 15',
            df[coluna] == '16 a 20', 
            df[coluna] == '21 ou mais',
            df[coluna].isin(['N√£o sei informar', 'N√£o se aplica'])

        ]
        
        choices = ['Baixa', 'M√©dia', 'Alta', 'Muito Alta', 'N√£o informado']
        df[f'{coluna}_cat_simples'] = np.select(conditions, choices, default='N√£o informado')

    return df

def transformar_categoricos_pequenos(df: pd.DataFrame) -> pd.DataFrame:
    """
    Transforma as colunas em valores num√©ricos e categorias ordenados
    """
    
    # Mapeamento para valores num√©ricos (ponto m√©dio dos intervalos)
    mapeamento_numerico = {
        'Nenhum': 0,
        '1': 1,
        '2': 2,
        '3 a 5': 4,  # ponto m√©dio
        '6 ou mais': 6,
        'N√£o sei informar': None,
        'N√£o se aplica': None,
        '': None
    }
    
    colunas_perifericos = [
        'webcams_disponiveis',
        'microfones_disponiveis', 
        'fones_disponiveis',
        'caixas_som_disponiveis',
        'notebooks_com_camera',
        'notebooks_com_caixa_som', 
        'notebooks_com_microfone',

        'notebooks_boas',
        'computadores_problema',

        'televisores',
        'projetores'
    
    ]
    
    for coluna in colunas_perifericos:
        if coluna not in df.columns:
            print(f"‚ö†Ô∏è Coluna {coluna} n√£o encontrada")
            continue
            
        print(f"\nüîç Analisando {coluna}:")
        print(f"Valores √∫nicos antes: {df[coluna].unique()}")
        print(f"Contagem de valores:\n{df[coluna].value_counts()}")
        
        # 1. Criar vers√£o num√©rica
        df[f'{coluna}_num'] = df[coluna].map(mapeamento_numerico)
        
        print(f"Valores num√©ricos criados:")
        print(f"M√≠nimo: {df[f'{coluna}_num'].min()}")
        print(f"M√°ximo: {df[f'{coluna}_num'].max()}")
        print(f"M√©dia: {df[f'{coluna}_num'].mean()}")
        print(f"Contagem de NaNs: {df[f'{coluna}_num'].isna().sum()}")
        
        ordem_categorias = ['Nenhum', '1', '2', '3 a 5', '6 ou mais', 'N√£o sei informar', 'N√£o se aplica']
        df[coluna] = pd.Categorical(df[coluna], categories=ordem_categorias, ordered=True)
        
        conditions = [
            df[coluna].isin(['Nenhum', '1']),
            df[coluna] == '2',
            df[coluna] == '3 a 5', 
            df[coluna] == '6 ou mais',
            df[coluna].isin(['N√£o sei informar', 'N√£o se aplica'])
        ]
        
        choices = ['Baixa', 'M√©dia', 'Alta', 'Muito Alta', 'N√£o informado']
        df[f'{coluna}_cat_simples'] = np.select(conditions, choices, default='N√£o informado')

    return df


def transformar_escala_ordenada(df: pd.DataFrame, coluna: str, ordem_categorias: list) -> pd.DataFrame:
    """
    Fun√ß√£o auxiliar para transformar qualquer coluna em categ√≥rica ordenada
    """
    if coluna not in df.columns:
        return df
        
    # Converter para categ√≥rica ordenada
    df[coluna] = pd.Categorical(
        df[coluna], 
        categories=ordem_categorias, 
        ordered=True
    )
    
    return df

def transformar_escalas_zero_dez(df: pd.DataFrame) -> pd.DataFrame:
    """
    Aplica transforma√ß√£o ordenada a todas as colunas de escala 0-10
    """
    mapeamento_numerico = {
        '0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5,
        '6': 6, '7': 7, '8': 8, '9': 9, '10': 10,
        'N√£o sei informar': None, 'N√£o se aplica': None,
    }
    
    # Definir a ordem natural para escala 0-10
    ordem_escala = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']
    
    # Colunas que s√£o escalas 0-10
    colunas_escala = ['qualidade_internet']
    
    for coluna in colunas_escala:
        if coluna not in df.columns:
            continue
            
        # 1. Criar vers√£o num√©rica
        df[f'{coluna}_num'] = df[coluna].map(mapeamento_numerico)
        
        # 2. Aplicar transforma√ß√£o ordenada usando a fun√ß√£o auxiliar
        df = transformar_escala_ordenada(df, coluna, ordem_escala)
        
        # 3. Criar categorias simplificadas
        conditions = [
            df[coluna].isin(['0', '1', '2', '3']),
            df[coluna].isin(['4', '5', '6']),
            df[coluna].isin(['7', '8']),
            df[coluna].isin(['9', '10']),
            df[coluna].isin(['N√£o sei informar', 'N√£o se aplica'])
        ]
        
        choices = ['Baixa (0-3)', 'M√©dia (4-6)', 'Alta (7-8)', 'Muito Alta (9-10)', 'N√£o informado']
        df[f'{coluna}_cat_simples'] = np.select(conditions, choices, default='N√£o informado')
    
    return df

def transformar_escala_ordenada(df: pd.DataFrame, coluna: str, ordem_categorias: list) -> pd.DataFrame:
    """
    Fun√ß√£o auxiliar para transformar qualquer coluna em categ√≥rica ordenada
    """
    if coluna not in df.columns:
        return df
        
    # Converter para categ√≥rica ordenada
    df[coluna] = pd.Categorical(
        df[coluna], 
        categories=ordem_categorias, 
        ordered=True
    )
    
    return df

def transformar_escalas_zero_dez(df: pd.DataFrame) -> pd.DataFrame:
    """
    Aplica transforma√ß√£o ordenada a todas as colunas de escala 0-10
    """
    mapeamento_numerico = {
        '0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5,
        '6': 6, '7': 7, '8': 8, '9': 9, '10': 10,
        'N√£o sei informar': None, 'N√£o se aplica': None,
    }
    
    # Definir a ordem natural para escala 0-10
    ordem_escala = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']
    
    # Colunas que s√£o escalas 0-10
    colunas_escala = ['qualidade_internet']
    
    for coluna in colunas_escala:
        if coluna not in df.columns:
            continue
            
        # 1. Criar vers√£o num√©rica
        df[f'{coluna}_num'] = df[coluna].map(mapeamento_numerico)
        
        # 2. Aplicar transforma√ß√£o ordenada usando a fun√ß√£o auxiliar
        df = transformar_escala_ordenada(df, coluna, ordem_escala)
        
        # 3. Criar categorias simplificadas
        conditions = [
            df[coluna].isin(['0', '1', '2', '3']),
            df[coluna].isin(['4', '5', '6']),
            df[coluna].isin(['7', '8']),
            df[coluna].isin(['9', '10']),
            df[coluna].isin(['N√£o sei informar', 'N√£o se aplica'])
        ]
        
        choices = ['Baixa (0-3)', 'M√©dia (4-6)', 'Alta (7-8)', 'Muito Alta (9-10)', 'N√£o informado']
        df[f'{coluna}_cat_simples'] = np.select(conditions, choices, default='N√£o informado')
    
    return df

def transformar_escalas_zero_cinco(df: pd.DataFrame) -> pd.DataFrame:
    """
    Aplica transforma√ß√£o ordenada a todas as colunas de escala 1-5
    """
    mapeamento_numerico = {
        '1': 1, '2': 2, '3': 3, '4': 4, '5': 5,
        'N√£o sei informar': None
    }
    
    # Definir a ordem natural para escala 1-5
    ordem_escala = ['1', '2', '3', '4', '5']
    
    # Colunas que s√£o escalas 1-5
    colunas_escala = ['competencia_tecnica_equipe']
    
    for coluna in colunas_escala:
        if coluna not in df.columns:
            continue
            
        # 1. Criar vers√£o num√©rica
        df[f'{coluna}_num'] = df[coluna].map(mapeamento_numerico)
        
        # 2. Aplicar transforma√ß√£o ordenada usando a fun√ß√£o auxiliar
        df = transformar_escala_ordenada(df, coluna, ordem_escala)
        
        # 3. Criar categorias simplificadas
        conditions = [
            df[coluna].isin(['1', '2']),
            df[coluna] == '3',
            df[coluna].isin(['4', '5']),
            df[coluna] == 'N√£o sei informar'
        ]
        
        choices = ['Baixa (1-2)', 'M√©dia (3)', 'Alta (4-5)', 'N√£o informado']
        df[f'{coluna}_cat_simples'] = np.select(conditions, choices, default='N√£o informado')
    
    return df

def tratar_sistemas_e_qualidade(df: pd.DataFrame) -> pd.DataFrame:
    """
    Trata as colunas Q25 (sistemas usados) e Q26 (qualidade dos dados).
    Cria colunas bin√°rias de uso e avalia√ß√£o por sistema.
    Detecta inconsist√™ncias entre uso e avalia√ß√£o.
    """

    # Lista de sistemas poss√≠veis (baseado nas colunas de qualidade)
    sistemas = [
        'SINASC', 'Vida+', 'E-SUS AB/SISAB', 'SINAN', 'GAL',
        'SIA-SUS', 'SIH-SUS', 'SIM', 'Sivep-Gripe', 'E-SUS Notifica', 'Sisvan'
    ]

    # Normalizar a coluna de sistemas usados
    df['sistemas_informacao_utilizados'] = df['sistemas_informacao_utilizados'].fillna('').str.strip()

    # Criar colunas bin√°rias de uso
    for sistema in sistemas:
        col_uso = f'usou_{sistema.lower().replace("-", "_").replace("+", "plus").replace(" ", "_")}'
        df[col_uso] = df['sistemas_informacao_utilizados'].str.contains(sistema, case=False, na=False).astype(int)

    # Criar colunas bin√°rias de avalia√ß√£o (se avaliou, o valor n√£o √© vazio ou "N√£o se aplica")
    for sistema in sistemas:
        col_qualidade = f'qualidade_{sistema.lower().replace("-", "_").replace("+", "plus").replace(" ", "_")}'
        col_avaliou = f'avaliou_{sistema.lower().replace("-", "_").replace("+", "plus").replace(" ", "_")}'

        if col_qualidade in df.columns:
            df[col_avaliou] = df[col_qualidade].notna() & (~df[col_qualidade].isin(['', 'N√£o se aplica'])).astype(int)
        else:
            df[col_avaliou] = 0  # Se n√£o existe coluna de qualidade, n√£o avaliou

    # Detectar inconsist√™ncias
    df['sistemas_inconsistentes'] = 0
    for sistema in sistemas:
        col_uso = f'usou_{sistema.lower().replace("-", "_").replace("+", "plus").replace(" ", "_")}'
        col_avaliou = f'avaliou_{sistema.lower().replace("-", "_").replace("+", "plus").replace(" ", "_")}'

        # Inconsist√™ncia: avaliou mas n√£o usou
        inconsistencia = (df[col_avaliou] == 1) & (df[col_uso] == 0)
        df.loc[inconsistencia, 'sistemas_inconsistentes'] += 1

    # Criar contadores
    df['total_sistemas_usados'] = df[[f'usou_{s.lower().replace("-", "_").replace("+", "plus").replace(" ", "_")}' for s in sistemas]].sum(axis=1)
    df['total_sistemas_avaliados'] = df[[f'avaliou_{s.lower().replace("-", "_").replace("+", "plus").replace(" ", "_")}' for s in sistemas]].sum(axis=1)

    return df

def criar_resumo_sistemas(df: pd.DataFrame) -> pd.DataFrame:
    """
    Cria uma tabela resumo com uso e qualidade m√©dia por sistema.
    """

    sistemas = [
        'SINASC', 'Vida+', 'E-SUS AB/SISAB', 'SINAN', 'GAL', 'SIA-SUS', 'SIH-SUS', 'SIM', 'Sivep-Gripe', 'E-SUS Notifica', 'Sisvan'
    ]

    # Mapeamento correto de sistema -> nomes reais das colunas
    col_map = {
        'SINASC': ('usou_sinasc', 'qualidade_sinasc'),
        'Vida+': ('usou_vidaplus', 'qualidade_vida_plus'),
        'E-SUS AB/SISAB': ('usou_e_sus_ab/sisab', 'qualidade_esus_sisab'),
        'SINAN': ('usou_sinan', 'qualidade_sinan'),
        'GAL': ('usou_gal', 'qualidade_gal'),
        'SIA-SUS': ('usou_sia_sus', 'qualidade_sia_sus'),
        'SIH-SUS': ('usou_sih_sus', 'qualidade_sih_sus'),
        'SIM': ('usou_sim', 'qualidade_sim'),
        'Sivep-Gripe': ('usou_sivep_gripe', 'qualidade_sivep_gripe'),
        'E-SUS Notifica': ('usou_e_sus_notifica', 'qualidade_esus_notifica'),
        'Sisvan': ('usou_sisvan', 'qualidade_sisvan')
    }

    qualidade_map = {
        'Muito Ruim': 1,
        'Ruim': 2, 
        'Bom': 3,
        'Muito bom': 4,
        'Excelente': 5
    }

    resumo = []
    for sistema in sistemas:
        col_uso, col_qualidade = col_map[sistema]
        
        uso = df[col_uso].sum()
        qualidades = df[col_qualidade].dropna().map(qualidade_map)
        
        if len(qualidades) > 0:
            qualidade_media = qualidades.mean()
        else:
            qualidade_media = None
        
        resumo.append({
            'sistema': sistema,
            'uso': uso,
            'qualidade_media': qualidade_media
        })
    
    resumo_df = pd.DataFrame(resumo)
    resumo_df = resumo_df[resumo_df['uso'] > 0]  # s√≥ quem foi usado
    return resumo_df

# FUN√á√ïES para INDICADORES ‚Äì PONTUA√á√ÉO POR DIMENS√ÉO

def _pontuar_pessoas(df: pd.DataFrame) -> pd.Series:
    """
    0-100 baseado em:
    - competencia_tecnica_equipe (1-5)
    - participa_qualificacoes
    - cultura_uso_dados
    - qtd_ferramentas (0-4+)
    """
    logger = logging.getLogger("ETL.ip_sala_situacao.pessoas")

    # ---- valores brutos ----
    comp_raw = pd.to_numeric(df['competencia_tecnica_equipe_num'], errors='coerce').fillna(1)
    comp = comp_raw / 5                                    # 0-1
    qual = df['participa_qualificacoes'].map({
        'Sim, regularmente (ao menos uma vez por ano)': 1,
        'Sim, mas esporadicamente': 0.5,
        'N√£o': 0
    }).fillna(0)
    cult = df['cultura_uso_dados'].map({
        'Sim, a an√°lise de dados √© central em nossas reuni√µes e planejamentos.': 1,
        'Em partes, usamos dados, mas as decis√µes ainda s√£o muito baseadas na experi√™ncia.': 0.5,
        'N√£o, os dados s√£o vistos mais como uma obriga√ß√£o de preenchimento do que como uma ferramenta de gest√£o.': 0
    }).fillna(0)
    ferr = np.minimum(df['qtd_ferramentas'].fillna(0), 4) / 4   # 0-1

    # ---- log de exemplo (primeira linha) ----
    if len(df) > 0:
        logger.info(f"Exemplo linha 0 -> comp: {comp.iloc[0]:.2f}, qual: {qual.iloc[0]:.2f}, "
                    f"cult: {cult.iloc[0]:.2f}, ferr: {ferr.iloc[0]:.2f}")

    # ---- score final 0-100 (sem duplicar *100) ----
    score = (
        comp * 40 +
        qual * 25 +
        cult * 25 +
        ferr * 10
    ) * 1
    return score.clip(0, 100)

def _pontuar_infraestrutura(df: pd.DataFrame) -> pd.Series:
    logger = logging.getLogger("ETL.ip_sala_situacao.infra")

    est = df['estacoes_trabalho_boas_num'].fillna(0) / 25
    note = df['notebooks_boas_num'].fillna(0) / 6
    net_ok = (df['internet_estavel'] == 'Sim').astype(int)
    net_not = pd.to_numeric(df['qualidade_internet_num'], errors='coerce').fillna(0) / 10
    sala = (df['sala_situacao'] == 'Sim, possui uma sala adequada').astype(int)
    cabo = (df['cabos_adaptadores'] == 'Sim, para todos os equipamentos').astype(int)

    if len(df) > 0:
        logger.info(f"Exemplo linha 0 -> est: {est.iloc[0]:.2f}, note: {note.iloc[0]:.2f}, "
                    f"net_ok: {net_ok.iloc[0]:.2f}, net_not: {net_not.iloc[0]:.2f}, "
                    f"sala: {sala.iloc[0]:.2f}, cabo: {cabo.iloc[0]:.2f}")

    score = (
        est * 30 +
        note * 15 +
        net_ok * 20 + net_not * 10 +
        sala * 20 +
        cabo * 5
    )  # <-- removido *100
    return score.clip(0, 100)

def _pontuar_processos(df: pd.DataFrame) -> pd.Series:
    logger = logging.getLogger("ETL.ip_sala_situacao.processos")

    # ---- etapas normalizadas 0-1 ----
    ind_def     = (df['indicadores_definidos']        == 'Sim').astype(int)
    dados_meta  = df['dados_subsidiam_metas'].map({'Sim': 1, 'Parcialmente': 0.5, 'N√£o': 0, 'N√£o sei informar': 0})
    meta_dados  = df['metas_base_dados'].map({'Sim': 1, 'Parcialmente': 0.5, 'N√£o': 0, 'N√£o sei informar': 0})
    fluxos      = (df['fluxos_formalizados']         == 'Sim').astype(int)
    rotina      = (df['rotina_validacao']            == 'Sim').astype(int)
    paineis     = df['paineis_tomada_decisao'].map({'Sim': 1, 'Parcialmente': 0.5, 'N√£o': 0, 'N√£o sei informar': 0})

    # ---- log amostral (5 primeiras) ----
    for i in range(min(5, len(df))):
        logger.info(f"idx {i} -> ind_def:{ind_def.iloc[i]:.2f} dados_meta:{dados_meta.iloc[i]:.2f} "
                    f"meta_dados:{meta_dados.iloc[i]:.2f} fluxos:{fluxos.iloc[i]:.2f} "
                    f"rotina:{rotina.iloc[i]:.2f} paineis:{paineis.iloc[i]:.2f}")

    score = (
        ind_def   * 20 +
        dados_meta * 15 +
        meta_dados * 15 +
        fluxos    * 15 +
        rotina    * 20 +
        paineis   * 15
    )  # j√° 0-100
    logger.info(f"ESTAT√çSTICA processos -> min:{score.min():.1f} | m√©dia:{score.mean():.1f} | max:{score.max():.1f}")
    return score.clip(0, 100)

def _pontuar_seguranca(df: pd.DataFrame) -> pd.Series:
    logger = logging.getLogger("ETL.ip_sala_situacao.seguranca")

    # ---- etapas normalizadas 0-1 ----
    lgpd        = df['conhecimento_lgpd'].map({'Sim': 1, 'Tenho uma no√ß√£o, mas n√£o conhe√ßo em detalhes': 0.5, 'N√£o': 0})
    treino      = df['treinamento_lgpd'].map({'Sim': 1, 'Apenas orienta√ß√µes informais': 0.5, 'N√£o': 0})
    acesso      = df['acesso_individualizado'].map({'Sim': 1, 'Em parte (alguns sistemas sim, outros n√£o)': 0.5, 'N√£o, os acessos s√£o compartilhados': 0})
    backup      = (df['protocolos_backup'] == 'Sim').astype(int)

    # ---- log amostral (5 primeiras) ----
    for i in range(min(5, len(df))):
        logger.info(f"idx {i} -> lgpd:{lgpd.iloc[i]:.2f} treino:{treino.iloc[i]:.2f} "
                    f"acesso:{acesso.iloc[i]:.2f} backup:{backup.iloc[i]:.2f}")

    score = (
        lgpd   * 30 +
        treino * 25 +
        acesso * 25 +
        backup * 20
    ) 
    logger.info(f"ESTAT√çSTICA seguranca -> min:{score.min():.1f} | m√©dia:{score.mean():.1f} | max:{score.max():.1f}")
    return score.clip(0, 100)

def adicionar_ip_sala_situacao(df: pd.DataFrame) -> pd.DataFrame:
    logger.info("Calculando IP-SalaSit...")
    df = df.copy()

    num_cols = ['competencia_tecnica_equipe_num', 'estacoes_trabalho_boas_num',
                'notebooks_boas_num', 'qualidade_internet_num', 'qtd_ferramentas']
    for c in num_cols:
        if c not in df.columns:
            logger.warning(f"Coluna {c} n√£o encontrada ‚Äì preenchendo com 0")
            df[c] = 0

    df['ip_pessoas'] = _pontuar_pessoas(df)
    df['ip_infra'] = _pontuar_infraestrutura(df)
    df['ip_processos'] = _pontuar_processos(df)
    df['ip_seguranca'] = _pontuar_seguranca(df)

    df['ip_sala_situacao'] = (
        0.30 * df['ip_pessoas'] +
        0.30 * df['ip_infra'] +
        0.25 * df['ip_processos'] +
        0.15 * df['ip_seguranca']
    ).round(2)

    logger.info("IP-SalaSit calculado com sucesso.")
    return df

# -------------------------------------------------------------------
# # TRANSFORM ‚Äì APLICA TRANSFORMA√á√ïES NOS DADOS
# -------------------------------------------------------------------
def transform(df: pd.DataFrame) -> pd.DataFrame:
    logger.info("Iniciando transforma√ß√µes...")
    
    df = rename_columns(df)
    df = normalizar_area_atuacao(df)
    df = transformar_atuacao_info(df)
    df = transformar_ferramentas_analise(df)
    df = transformar_categoricos_grandes(df)
    df = transformar_categoricos_pequenos(df)
    df = transformar_escalas_zero_dez(df)
    df = transformar_escalas_zero_cinco(df)
    df = tratar_sistemas_e_qualidade(df)
    df = adicionar_ip_sala_situacao(df)

    logger.info("Transforma√ß√£o conclu√≠da.")
    return df

# -------------------------------------------------------------------
# LOAD ‚Äì CRIA ABA E ESCREVE DADOS NA MESMA PLANILHA
# -------------------------------------------------------------------
def load_to_sheet(client, sheet_id: str, df: pd.DataFrame, new_tab: str = "DadosEtl"):
    logger.info(f"Atualizando aba '{new_tab}' sem excluir...")

    sh = client.open_by_key(sheet_id)

    try:
        ws = sh.worksheet(new_tab)
        logger.info(f"Aba '{new_tab}' encontrada. Limpando e sobrescrevendo...")
    except gspread.exceptions.WorksheetNotFound:
        logger.info(f"Aba '{new_tab}' n√£o existe. Criando...")
        ws = sh.add_worksheet(title=new_tab, rows=str(len(df) + 5), cols=str(len(df.columns) + 5))

    ws.clear()

    df_preparado = df.copy()
    for col in df_preparado.columns:
        if df_preparado[col].dtype.name == 'category':
            df_preparado[col] = df_preparado[col].astype(str)
    df_preparado = df_preparado.fillna('')

    values = [df_preparado.columns.tolist()] + df_preparado.values.tolist()
    ws.update(values)

    ws.freeze(rows=1)

    logger.info(f"Aba '{new_tab}' atualizada com sucesso ‚Äî sem excluir!")

# -------------------------------------------------------------------
# MAIN
# -------------------------------------------------------------------
def main():
    SHEET_ID = "..."
    TAB = "BaseBruta"
    NEW_TAB = "DadosEtl"

    df, client = extract(SHEET_ID, TAB)
    df = transform(df)
    
    load_to_sheet(client, SHEET_ID, df, NEW_TAB)

    logger.info("ETL COMPLETO! Todas as abas formatadas como tabelas.")


if __name__ == "__main__":
    main()