import json
import os
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
import logging
from datetime import datetime
import numpy as np
import time



# CONFIGURA√á√ÉO DO LOGGER
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = logging.getLogger("ETL")


# CARREGA CREDENCIAIS DO GOOGLE SHEETS DAS VARI√ÅVEIS DE AMBIENTE
def load_google_credentials():
    json_path = os.environ.get("GOOGLE_CREDENTIALS_JSON")
    if not json_path:
        raise ValueError("Vari√°vel GOOGLE_CREDENTIALS_JSON n√£o definida.")

    scopes = [
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive"
    ]

    return Credentials.from_service_account_file(json_path, scopes=scopes)



# EXTRACT ‚Äì LE O GOOGLE SHEETS
def extract(sheet_id: str, tab_name: str):
    logger.info(f"Lendo planilha: {sheet_id} | Aba: {tab_name}")

    creds = load_google_credentials()
    client = gspread.authorize(creds)

    ws = client.open_by_key(sheet_id).worksheet(tab_name)

    # Mais r√°pido que get_all_records
    values = ws.get_all_values()
    df = pd.DataFrame(values[1:], columns=values[0])

    logger.info(f"Linhas carregadas: {len(df)}")
    return df, client


# TRANSFORM ‚Äì TRATAMENTO PADR√ÉO (MODIFIQUE COMO QUISER)
def normalizar_area_atuacao(df: pd.DataFrame) -> pd.DataFrame:
    """
    Normaliza a coluna 'area_atuacao' agrupando varia√ß√µes em categorias consistentes
    """
    
    # Mapeamento de normaliza√ß√£o
    mapeamento_areas = {
        # Vazio
        '': "Desconhecido",

        # Subcoordenadorias
        'Subcoordenadoria de Aten√ß√£o e Vigil√¢ncia √† Sa√∫de': 'Subcoordenadoria de Aten√ß√£o e Vigil√¢ncia',
        'Subcoordenadoria administrativa': 'Subcoordenadoria Administrativa',
        'Subcoordenadoria de Aten√ß√£o e Vigil√¢ncia √† Sa√∫de': 'Subcoordenadoria de Aten√ß√£o e Vigil√¢ncia',
        
        # √Åreas administrativas
        '√Årea administrativa': 'Administrativo',
        'T√©cnica administrativa': 'Administrativo',
        'Auxiliar administrativo': 'Administrativo',
        'T√©cnica Administrativa': 'Administrativo',
        '√Årea t√©cnica': 'Administrativo',
        'Tecnica Administrativa / RH': 'Administrativo/RH',
        'Administrativo': 'Administrativo',
        'admistrativa de apoio': 'Administrativo',
        'Administra√ß√£o': 'Administrativo',
        'Auxiliar administrativa': 'Administrativo',
        'Administra√ß√£o -': 'Administrativo',
        'Apoio administrativo': 'Administrativo',
        'Administrativa - Programa Sa√∫de da mulher e Fichas do Sinan': 'Administrativo',
        'administrativa': 'Administrativo',
        'Admistrativo': 'Administrativo',
        'Setor administrativo': 'Administrativo',
        'Servi√ßo de a√ß√µes do administrativo': 'Administrativo',
        'Assistente administrativo - digita√ß√£o de fichas, documenta√ß√£o, envio e coleta de documenta√ß√£o.': 'Administrativo',
        'Auxiliar administrativo de a√ß√µes': 'Administrativo',
        'T√©cnica administrativa - suporte ao servi√ßo': 'Administrativo',
        'Administrativa': 'Administrativo',
        'Administrativo - setor de a√ß√µes': 'Administrativo',
        'Tecnico de nivel medio I atendimento': 'Administrativo',
        
        # RH
        'Chefe de RH': 'RH',
        'Chefia de RH': 'RH',
        'Setor Administrativo/RH': 'RH',
        'RH': 'RH',
        
        # Vigil√¢ncia Epidemiol√≥gica (VIEP)
        'Vigil√¢ncia epidemiol√≥gica': 'Vigil√¢ncia Epidemiol√≥gica',
        'Vigil√¢ncia epidemiol√≥gica': 'Vigil√¢ncia Epidemiol√≥gica',
        'Tecnica da VIEP': 'Vigil√¢ncia Epidemiol√≥gica',
        'VIEP': 'Vigil√¢ncia Epidemiol√≥gica',
        'T√©cnica da VIEP': 'Vigil√¢ncia Epidemiol√≥gica',
        'VIEP- VIGIL√ÇNCIA EPIDEMIOL√ìGICA': 'Vigil√¢ncia Epidemiol√≥gica',
        'Tec. VIEP': 'Vigil√¢ncia Epidemiol√≥gica',
        'T√©cnico da viep': 'Vigil√¢ncia Epidemiol√≥gica',
        'Chefia de viep': 'Vigil√¢ncia Epidemiol√≥gica',
        'Chefia da vigil√¢ncia epidemiol√≥gica': 'Vigil√¢ncia Epidemiol√≥gica',
        'Chefia do setor Vigil√¢ncia Epidemiol√≥gica e Sistemas de Informa√ß√£o em Sa√∫de': 'Vigil√¢ncia Epidemiol√≥gica',
        'Operadora de Sistemas da VIEP': 'Vigil√¢ncia Epidemiol√≥gica',
        'T√©cnica de Enfermagem- VIEP': 'Vigil√¢ncia Epidemiol√≥gica',
        'vigilancia epidemiologica': 'Vigil√¢ncia Epidemiol√≥gica',
        
        # Vigil√¢ncia Sanit√°ria (VISA)
        'Protocolo da VISA': 'Vigil√¢ncia Sanit√°ria',
        'Vigil√¢ncia sanit√°ria': 'Vigil√¢ncia Sanit√°ria',
        'Fiscal de controle sanit√°rio': 'Vigil√¢ncia Sanit√°ria',
        'Fiscal dr controle sanit√°rio': 'Vigil√¢ncia Sanit√°ria',
        'Vigil√¢ncia Sanit√°ria do munic√≠pio': 'Vigil√¢ncia Sanit√°ria',
        'Encarregada de Apoio, a frente da recep√ß√£o, do protocolo, da VISA (vigil√¢ncia Sanit√°ria)': 'Vigil√¢ncia Sanit√°ria',
        
        # Enfermagem e T√©cnicos de Enfermagem
        'T√©cnico de enfermagem': 'Enfermagem',
        'Tecnico de enfermagem': 'Enfermagem',
        'TECNICA DE ENFERMAGEM': 'Enfermagem',
        'Tecnica de enfermagem': 'Enfermagem',
        'T√©cnica em enfermagem': 'Enfermagem',
        'T√©cnica de Enfermagem': 'Enfermagem',
        'T√©cnico de enfermagem': 'Enfermagem',
        'Enfermeira- PAI DA VISA DSB': 'Enfermagem',
        'Enfermeira da area de a√ß√µes.': 'Enfermagem',
        'Estagi√°ria de Enfermagem': 'Enfermagem',
        
        # A√ß√µes e Servi√ßos / Chefias
        'Chefe de a√ß√µes ou servi√ßos': 'Chefia de A√ß√µes e Servi√ßos',
        'Chefia de a√ß√µes e sa√∫de': 'Chefia de A√ß√µes e Sa√∫de',
        'Chefia de a√ß√µes e servi√ßos': 'Chefia de A√ß√µes e Servi√ßos',
        'Chefia de vigil√¢ncia epidemiol√≥gica': 'Chefia de Vigil√¢ncia Epidemiol√≥gica',
        'Chefia de setor da vigil√¢ncia Epidemiologia': 'Chefia de Vigil√¢ncia Epidemiol√≥gica',
        'Chefe da Visa do Distrito Sanit√°rio de Brotas': 'Chefia de Vigil√¢ncia Epidemiol√≥gica',
        'A√á√ïES E SERVI√áOS': 'A√ß√µes e Servi√ßos',
        'A√ß√µes e Servi√ßos': 'A√ß√µes e Servi√ßos',
        'CHEFIA A√á√ïES B√ÅSICAS': 'Chefia de A√ß√µes e Servi√ßos',
        'A√ß√µes B√°sicas': 'A√ß√µes e Servi√ßos',
        'A√ß√µes': 'A√ß√µes e Servi√ßos',
        'T√©cnica ligada a chefia de a√ß√µes': 'A√ß√µes e Servi√ßos',
        'Area t√©cnica  - Chefia de A√ß√µes e Servi√ßos': 'A√ß√µes e Servi√ßos',
        'T√©cnica vinculada a chefia de a√ß√µes b√°sicas': 'A√ß√µes e Servi√ßos',
        'T√©cnico de refer√™ncia de pastas na chefia de a√ß√µes e servi√ßos': 'A√ß√µes e Servi√ßos',
        
        # √Åreas T√©cnicas Especializadas
        'Refer√™ncia t√©cnica das a√ß√µes de alimenta√ß√£o e nutri√ß√£o': '√Årea T√©cnica - Nutri√ß√£o',
        'T√©cnico de refer√™ncia programa de nutri√ß√£o': '√Årea T√©cnica - Nutri√ß√£o',
        '√Årea t√©cnica de alimenta√ß√£o e nutri√ß√£o': '√Årea T√©cnica - Nutri√ß√£o',
        'Profissional integrada a sa√∫de - Nutricionista.': '√Årea T√©cnica - Nutri√ß√£o',

        'T√©cnica de pasta de agravo': '√Årea T√©cnica - Agravos',      

        'T√©cnica de refer√™ncia': '√Årea T√©cnica - Refer√™ncia',  
        'Refer√™ncia t√©cnica': '√Årea T√©cnica - Refer√™ncia',
        
        'Refer√™ncia t√©cnica de sa√∫de da mulher e ist': '√Årea T√©cnica - Sa√∫de da Mulher',
        'Refer√™ncia t√©cnica Sa√∫de da mulher, curativos especiais, doen√ßa renal cr√¥nica e oncologia,territorializa√ß√£o': '√Årea T√©cnica - Sa√∫de da Mulher',
        
        'T√©cnica de refr√™ncia em Sa√∫de da Crian√ßa, Sa√∫de do Adolescentes, Sa√∫de da Pessoa com Defici√™ncia e Programa de Sa√∫de na Escola': '√Årea T√©cnica - Sa√∫de da Crian√ßa/Adolescente',
        'Respons√°vel pelas pastas: sa√∫de do adolescente, sa√∫de da pessoa com defici√™ncia, doen√ßas cr√¥nicas, telessaude e viol√™ncia parte a√ß√µes': '√Årea T√©cnica - Programas Especiais',
        
        'Respons√°vel t√©cnica pelo programa sa√∫de na escola e do adolescente': '√Årea T√©cnica - PSE',
        'Respons√°vel t√©cnica de imuniza√ß√£o': '√Årea T√©cnica - Imuniza√ß√£o',
        'referencia t√©cnica de imuniza√ß√£o': '√Årea T√©cnica - Imuniza√ß√£o',
        
        # Epidemiologia e An√°lise de Dados
        'Setor de Epidemiologia e An√°lise da Informa√ß√£o em Sa√∫de': 'Epidemiologia e An√°lise de Dados',
        'Nugetes/ GT Plan': 'Epidemiologia e An√°lise de Dados',
        'NUGETS': 'Epidemiologia e An√°lise de Dados',
        'NUGETES': 'Epidemiologia e An√°lise de Dados',
        
        # Sa√∫de Bucal
        'Dentista distrital': 'Sa√∫de Bucal',
        'Odont√≥loga distrital': 'Sa√∫de Bucal',
        'Apoiadora dos Dentistas.': 'Sa√∫de Bucal',
        
        # Farm√°cia
        'Farmac√™utico do distrito e do CAPS': 'Farm√°cia',
        'Farmac√™utica Distrital': 'Farm√°cia',
        'Assist√™ncia Farmac√™utica': 'Farm√°cia',
        'Assist√™ncia Farmac√™utica Distrital': 'Farm√°cia',
        
        # Outras categorias espec√≠ficas
        'Refer√™ncia T√©cnica Curativos': 'Curativos Especiais',
        'T√©cnica de refer√™ncia de curativos especiais': 'Curativos Especiais',
        
        '√Årea t√©cnica tuberculose e vigil√¢ncia em Sa√∫de do Trabalhador': 'Vigil√¢ncia Sa√∫de do Trabalhador',
        '√Årea t√©cnica de sa√∫de da crian√ßa, adolescente, doen√ßas cr√¥nica, tabagismo e PSE.': '√Årea T√©cnica - Programas Especiais',
        
        'Referenccia de Investiga√ß√£o de √≤bitos Especiais': 'Vigil√¢ncia do √ìbito',
        'Sanitarista da Vigil√¢ncia Epidemiol√≥gica- Vigil√¢ncia do √≥bito': 'Vigil√¢ncia do √ìbito',
        
        'Sanitarista': 'Sanitarista',
        
        # TI e Suporte T√©cnico
        'TI do distrito': 'TI/Suporte T√©cnico',
        'T√©cnico de Inform√°tica': 'TI/Suporte T√©cnico',
        'NTI': 'TI/Suporte T√©cnico',
        'Centro de Processamento de Dados': 'TI/Suporte T√©cnico',
        
        # Servi√ßos Gerais
        'Servi√ßo gerais': 'Servi√ßos Gerais',
        'Servi√ßos Gerais': 'Servi√ßos Gerais',
        'Motorista': 'Servi√ßos Gerais',
        
        # Coordena√ß√£o e Assist√™ncia
        'Assistente da coordena√ß√£o': 'Coordena√ß√£o/Assist√™ncia',
        'Subcoordenador Administrativo': 'Coordena√ß√£o/Assist√™ncia',
        
        # Outros
        'POP ruas, Vacina, a√ß√µes externas...': 'A√ß√µes Externas/Comunit√°rias',
        'Digitadora': 'Administrativo',
        'T√©cnico': 'T√©cnico',
        'T√©cnico Distrital': 'T√©cnico',
        't√©cnico distrital': 'T√©cnico',
        'referencia tecnica': 'Refer√™ncia T√©cnica',
        'T√©cnica de Refer√™ncia das pastas Rede Alyne / PICS e Sa√∫de do Homem': 'Refer√™ncia T√©cnica',
        'vigilancia': 'Vigil√¢ncia',
        'Ouvidoria': 'Ouvidoria',
        'Sala de Imuniza√ß√£o': 'Imuniza√ß√£o',
        'Vacina√ß√£o': 'Imuniza√ß√£o',
        'Diretoria de Vigil√¢ncia √† Sa√∫de': 'Diretoria',
        'Setor de A√ß√µes e Servi√ßos de Sa√∫de': 'A√ß√µes e Servi√ßos',
        'Setor de Administra√ß√£o e Desenvolvimento de Pessoal': 'RH'
    }
    
    # LIMPAR ESPA√áOS EXTRAS ANTES DO MAPEAMENTO
    df['area_atuacao_limpa'] = df['area_atuacao'].str.strip()
    
    # Aplicar o mapeamento na coluna LIMPA
    df['area_atuacao_normalizada'] = df['area_atuacao_limpa'].map(mapeamento_areas)
    
    # Debug: ver quantos foram mapeados
    mapeados = df['area_atuacao_normalizada'].notna().sum()
    print(f"Valores mapeados: {mapeados}/{len(df)}")
    
    # IDENTIFICAR VALORES N√ÉO MAPEADOS
    nao_mapeados = df[df['area_atuacao_normalizada'].isna()]['area_atuacao_limpa'].unique()
    print(f"Valores n√£o mapeados ({len(nao_mapeados)}):")
    for valor in nao_mapeados:
        print(f"  '{valor}'")
    
    # SUBSTITUIR a coluna original pela normalizada
    df['area_atuacao'] = df['area_atuacao_normalizada'].fillna(df['area_atuacao_limpa'])
    
    # Remover colunas tempor√°rias
    df = df.drop(['area_atuacao_limpa', 'area_atuacao_normalizada'], axis=1)
    
    return df

def rename_columns(df: pd.DataFrame) -> pd.DataFrame:
    """
    Renomeia as colunas do DataFrame conforme o mapeamento fornecido.
    """
    rename_map = {
        "Carimbo de data/hora": "timestamp",
        "1 - Distrito Sanit√°rio (DS) ao qual voc√™ est√° vinculado": "ds_vinculado",
        "2 - Voc√™ √© coordenador do DS?": "coord_ds",
        "3  - Se n√£o, qual a sua √°rea de atua√ß√£o no DS?": "area_atuacao",
        "4 - Na sua √°rea de atua√ß√£o, voc√™ trabalha diretamente com a coleta, an√°lise ou gest√£o da informa√ß√£o?": "atuacao_info",
        "6 - Voc√™ participa de qualifica√ß√µes sobre an√°lise de dados, sistemas de informa√ß√£o ou planejamento em sa√∫de?": "participa_qualificacoes",
        "7 - Na sua opini√£o existe,  por parte dos profissionais, uma cultura de valoriza√ß√£o e uso de dados para a tomada de decis√£o no dia a dia do Distrito Sanit√°rio?": "cultura_uso_dados",
        "8 - Quais ferramentas s√£o mais utilizadas por voc√™ para analisar dados?": "ferramentas_analise",
        "9 - O distrito sanit√°rio de sa√∫de possui esta√ß√µes de trabalho (computador, teclado, mouse e monitor) em condi√ß√µes adequadas de uso? Quantas? ": "estacoes_trabalho_boas",
        "10 - Quantos computadores de mesa est√£o instalados, mas apresentam problemas recorrentes (lentid√£o, defeitos de hardware, etc.)?": "computadores_problema",
        "11 - O Distrito Sanit√°rio possui notebooks em condi√ß√µes de uso? Se sim, quantos?": "notebooks_boas",
        "11.1 - Se respondeu sim na pergunta anterior, quantos desses notebooks possuem c√¢mera, microfone e alto-falantes integrados e funcionais?  [C√¢meras (webcams)]": "notebooks_com_camera",
        "11.1 - Se respondeu sim na pergunta anterior, quantos desses notebooks possuem c√¢mera, microfone e alto-falantes integrados e funcionais?  [Caixas de som]": "notebooks_com_caixa_som",
        "11.1 - Se respondeu sim na pergunta anterior, quantos desses notebooks possuem c√¢mera, microfone e alto-falantes integrados e funcionais?  [Microfones]": "notebooks_com_microfone",
        "12 - Para realizar reuni√µes remotas (videoconfer√™ncias), marque quantos dos seguintes itens est√£o dispon√≠veis e em condi√ß√£o de uso no Distrito Sanit√°rio: [C√¢meras (webcams)]": "webcams_disponiveis",
        "12 - Para realizar reuni√µes remotas (videoconfer√™ncias), marque quantos dos seguintes itens est√£o dispon√≠veis e em condi√ß√£o de uso no Distrito Sanit√°rio: [Microfones (de mesa ou headsets):]": "microfones_disponiveis",
        "12 - Para realizar reuni√µes remotas (videoconfer√™ncias), marque quantos dos seguintes itens est√£o dispon√≠veis e em condi√ß√£o de uso no Distrito Sanit√°rio: [Fones de ouvido (headsets ou simples):]": "fones_disponiveis",
        "12 - Para realizar reuni√µes remotas (videoconfer√™ncias), marque quantos dos seguintes itens est√£o dispon√≠veis e em condi√ß√£o de uso no Distrito Sanit√°rio: [Caixas de som (para uso coletivo em sala):]": "caixas_som_disponiveis",
        "13 - O Distrito Sanit√°rio possui televisores ou projetores que podem ser conectados a computadores/notebooks para apresenta√ß√µes? Se sim, quantos?  [Televisor]": "televisores",
        "14 - Existem cabos (ex: HDMI) ou adaptadores dispon√≠veis e funcionais para conectar os computadores a esses televisores/projetores?": "cabos_adaptadores",
        "15 - Nos √∫ltimos 6 meses, o Distrito Sanit√°rio possuiu conex√£o est√°vel com a internet, permitindo o uso de videoconfer√™ncias e acesso a sistemas de informa√ß√£o em sa√∫de online e pain√©is de BI?": "internet_estavel",
        "15.1 - Se sim, em uma escala de 0 (p√©ssima) a 10 (excelente), como voc√™ avalia a qualidade geral (velocidade e estabilidade) da internet?": "qualidade_internet",
        "16 - A rede de internet no Distrito Sanit√°rio √©:": "tipo_rede_internet",
        "17 - O acesso √† rede Wi-Fi, se existente, √©:": "acesso_wifi",
        "18 - A estrutura el√©trica do Distrito Sanit√°rio suporta a inser√ß√£o de novos equipamentos tecnol√≥gicos (Ex: mais computadores, televisores, etc.)?": "estrutura_eletrica_suporta",
        "19 - O Distrito Sanit√°rio possui uma sala adequada para a realiza√ß√£o de reuni√µes em grupo e que possa abrigar a estrutura da Sala de Situa√ß√£o (proje√ß√£o de pain√©is, computadores, etc.)?": "sala_situacao",
        "19.1 - Se possui uma sala, ela √© climatizada (com ar-condicionado em funcionamento)?": "sala_climatizada",
        "20 - H√° indicadores definidos para monitorar o desempenho das a√ß√µes de sa√∫de acompanhadas pela equipe t√©cnica distrital?": "indicadores_definidos",
        "21 - As informa√ß√µes e an√°lises de dados geradas no Distrito Sanit√°rio subsidiam a elabora√ß√£o das metas para a Programa√ß√£o Operativa Anual (POA)?": "dados_subsidiam_metas",
        "21.1 - Se sim na pergunta anterior, descreva brevemente quais s√£o os principais indicadores acompanhados.": "principais_indicadores",
        "22 - As metas distritais s√£o definidas a partir da an√°lise dos dados?": "metas_base_dados",
        "23 - Existem meios de comunica√ß√£o entre o Distrito Sanit√°rio e as √°reas t√©cnicas do N√≠vel Central para dialogar sobre os indicadores por territ√≥rio?": "comunicacao_nivel_central",
        "23.1 - Se sim, descreva quais os meios de comunica√ß√£o utilizados (e-mail, reuni√µes, of√≠cios, grupos de mensagens, etc.) e com quais √°reas t√©cnicas.": "meios_comunicacao",
        "24 - H√° periodicidade definida para atualiza√ß√£o e revis√£o das metas estrat√©gicas que comp√µem a POA do Distrito Sanit√°rio?": "periodicidade_revisao_metas",
        "24.1 - Se sim, qual a periodicidade?": "periodicidade_metas",
        "25 - Quais bases de dados dos Sistemas de Informa√ß√£o em Sa√∫de (SIS), elencados abaixo, voc√™ utiliza para tabula√ß√£o e an√°lise dos dados no Distrito Sanit√°rio?": "sistemas_informacao_utilizados",
        "26 - Apenas para os sistemas escolhidos na quest√£o anterior, avalie a qualidade dos dados desses sistemas refletindo em suas dimens√µes de qualidade. [SINASC]": "qualidade_sinasc",
        "26 - Apenas para os sistemas escolhidos na quest√£o anterior, avalie a qualidade dos dados desses sistemas refletindo em suas dimens√µes de qualidade. [Vida+]": "qualidade_vida_plus",
        "26 - Apenas para os sistemas escolhidos na quest√£o anterior, avalie a qualidade dos dados desses sistemas refletindo em suas dimens√µes de qualidade. [E-SUS AB/SISAB]": "qualidade_esus_sisab",
        "26 - Apenas para os sistemas escolhidos na quest√£o anterior, avalie a qualidade dos dados desses sistemas refletindo em suas dimens√µes de qualidade. [SINAN]": "qualidade_sinan",
        "26 - Apenas para os sistemas escolhidos na quest√£o anterior, avalie a qualidade dos dados desses sistemas refletindo em suas dimens√µes de qualidade. [GAL]": "qualidade_gal",
        "26 - Apenas para os sistemas escolhidos na quest√£o anterior, avalie a qualidade dos dados desses sistemas refletindo em suas dimens√µes de qualidade. [SIA-SUS]": "qualidade_sia_sus",
        "26 - Apenas para os sistemas escolhidos na quest√£o anterior, avalie a qualidade dos dados desses sistemas refletindo em suas dimens√µes de qualidade. [SIH-SUS]": "qualidade_sih_sus",
        "26 - Apenas para os sistemas escolhidos na quest√£o anterior, avalie a qualidade dos dados desses sistemas refletindo em suas dimens√µes de qualidade. [SIM]": "qualidade_sim",
        "26 - Apenas para os sistemas escolhidos na quest√£o anterior, avalie a qualidade dos dados desses sistemas refletindo em suas dimens√µes de qualidade. [Sivep-Gripe]": "qualidade_sivep_gripe",
        "26 - Apenas para os sistemas escolhidos na quest√£o anterior, avalie a qualidade dos dados desses sistemas refletindo em suas dimens√µes de qualidade. [E-SUS Notifica]": "qualidade_esus_notifica",
        "26 - Apenas para os sistemas escolhidos na quest√£o anterior, avalie a qualidade dos dados desses sistemas refletindo em suas dimens√µes de qualidade. [Sisvan]": "qualidade_sisvan",
        "27 - Em rela√ß√£o aos dados digitados no Distrito Sanit√°rio, os fluxos de coleta e digita√ß√£o est√£o formalizados com as unidades de sa√∫de do territ√≥rio? (Ex: Fichas do SINAN que s√£o oriundas de unidades hospitalares)": "fluxos_formalizados",
        "28 - Existe rotina de confer√™ncia e valida√ß√£o da consist√™ncia dos dados que s√£o digitados no Distrito Sanit√°rio?": "rotina_validacao",
        "29 - Na sua opini√£o, a equipe respons√°vel pelo registro dos dados √© devidamente treinada?": "equipe_treinada",
        "30 - Quais foram as a√ß√µes (planejamento, interven√ß√µes, etc.) realizadas a partir dos dados tabulados no Distrito Sanit√°rio?": "acoes_base_dados",
        "31 - Os resultados dos indicadores s√£o comparados com s√©ries hist√≥ricas ou padr√µes de refer√™ncia para an√°lise de tend√™ncias?": "comparacao_series_historicas",
        "32 - H√° momentos institucionais de devolutiva e discuss√µes dos resultados com as equipes das unidades de sa√∫de? ": "devolutiva_resultados",
        "33 - Os boletins, informes ou comunicados com resultados dos indicadores de sa√∫de analisados s√£o discutidos com as unidades de sa√∫de do territ√≥rio? ": "discussao_boletins",
        "34 - Os pain√©is da Sala de Situa√ß√£o est√£o sendo utilizados para a tomada de decis√£o? ": "paineis_tomada_decisao",
        "34.1 - Se sim, especificar quais pain√©is s√£o mais utilizados. ": "paineis_utilizados",
        "35 - Na sua opini√£o, existe est√≠mulo √† inova√ß√£o e ao uso de novas ferramentas digitais para an√°lise de dados no  Distrito Sanit√°rio?": "estimulo_inovacao",
        "36 - Voc√™ compreende o papel estrat√©gico da Sala de Situa√ß√£o como uma ferramenta de apoio √† gest√£o?": "compreensao_sala_situacao",
        "37 - O Distrito Sanit√°rio tem alguma unidade de sa√∫de que utiliza a telessa√∫de para a realiza√ß√£o de consultas ou atendimentos remotos? ": "telessaude",
        "38 - Voc√™ sabe o que √© e qual o objetivo da Lei Geral de Prote√ß√£o de Dados Pessoais (LGPD)?": "conhecimento_lgpd",
        "39 - Voc√™ j√° recebeu treinamentos ou orienta√ß√µes formais sobre a confidencialidade das informa√ß√µes de sa√∫de e a conformidade com a LGPD?": "treinamento_lgpd",
        "40 - O acesso aos sistemas de informa√ß√£o √© controlado por n√≠veis de permiss√£o individualizados (cada profissional com seu pr√≥prio login e senha)?": "acesso_individualizado",
        "41 - Existem protocolos de backup e recupera√ß√£o de dados para os sistemas que s√£o alimentados localmente no Distrito Sanit√°rio?": "protocolos_backup",
        "5 - Em uma escala de 1 (nenhuma) a 5 (muita), como voc√™ avalia a compet√™ncia t√©cnica da equipe do distrito para analisar e interpretar indicadores de sa√∫de? [.]": "competencia_tecnica_equipe",
        "13 - O Distrito Sanit√°rio possui televisores ou projetores que podem ser conectados a computadores/notebooks para apresenta√ß√µes? Se sim, quantos?  [Projetor]": "projetores"
    }

    df = df.rename(columns=rename_map)
    return df

def transformar_atuacao_info(df: pd.DataFrame) -> pd.DataFrame:
    """
    Transforma a coluna de m√∫ltipla escolha em colunas bin√°rias individuais
    """
    
    
    # Criar colunas bin√°rias para cada op√ß√£o
    df['atuacao_coleta'] = df['atuacao_info'].str.lower().str.strip().str.contains('coleta', na=False).astype(int)
    df['atuacao_analise'] = df['atuacao_info'].str.lower().str.strip().str.contains('an√°lise', na=False).astype(int)
    df['atuacao_gestao'] = df['atuacao_info'].str.lower().str.strip().str.contains('gest√£o', na=False).astype(int)
    df['atuacao_nao'] = (df['atuacao_info'].str.lower().str.strip() == 'n√£o').astype(int)
    
    # Debug: verificar se as colunas foram criadas
    '''
    print("Colunas criadas:")
    print(f"Coleta: {df['atuacao_coleta'].sum()}")
    print(f"An√°lise: {df['atuacao_analise'].sum()}")
    print(f"Gest√£o: {df['atuacao_gestao'].sum()}")
    print(f"N√£o: {df['atuacao_nao'].sum()}")
    '''
    
    # Agora criar as colunas combinadas
    df['atuacao_multipla'] = (df['atuacao_coleta'] + df['atuacao_analise'] + df['atuacao_gestao'] > 1).astype(int)
    df['atuacao_apenas_uma'] = (df['atuacao_coleta'] + df['atuacao_analise'] + df['atuacao_gestao'] == 1).astype(int)
    
    # Criar categorias combinadas
    conditions = [
        (df['atuacao_coleta'] == 1) & (df['atuacao_analise'] == 1) & (df['atuacao_gestao'] == 1),
        (df['atuacao_coleta'] == 1) & (df['atuacao_analise'] == 1),
        (df['atuacao_analise'] == 1) & (df['atuacao_gestao'] == 1),
        (df['atuacao_coleta'] == 1) & (df['atuacao_gestao'] == 1),
        (df['atuacao_coleta'] == 1),
        (df['atuacao_analise'] == 1),
        (df['atuacao_gestao'] == 1),
        (df['atuacao_nao'] == 1)
    ]
    
    choices = [
        'Coleta+An√°lise+Gest√£o',
        'Coleta+An√°lise',
        'An√°lise+Gest√£o',
        'Coleta+Gest√£o',
        'Apenas Coleta',
        'Apenas An√°lise',
        'Apenas Gest√£o',
        'Nenhuma'
    ]
    
    df['atuacao_categoria'] = np.select(conditions, choices, default='Outro')

    '''
    print("Distribui√ß√£o das categorias:")
    print(df['atuacao_categoria'].value_counts())
    '''
    return df

def transformar_ferramentas_analise(df: pd.DataFrame) -> pd.DataFrame:
    """
    Transforma a coluna de ferramentas de an√°lise em colunas bin√°rias
    """
    
    # Mapeamento b√°sico das ferramentas padr√£o
    mapeamento_ferramentas = {
        'Planilhas (Excel, Google Sheets, etc.)': 'Planilhas',
        'Sistemas de tabula√ß√£o do SUS (Tabwin, TabNet, etc.)': 'Sistemas SUS', 
        'Pain√©is de BI (Qlik Sense, Power BI, Looker Studio, Oracle, Sistema de Monitoramento da APS, etc.)': 'Pain√©is BI',
        'Apresenta√ß√µes (PowerPoint, Google Slides, etc.)': 'Apresenta√ß√µes',
    }
    
    def categorizar_ferramentas(texto):
        if pd.isna(texto) or texto == '':
            return set(['Outras Ferramentas'])
        
        texto = str(texto).strip().lower()
        categorias = set()
        
        # Verificar se √© "nenhuma ferramenta" ou similar
        if any(phrase in texto for phrase in ['nenhuma ferramenta', 'n√£o faz an√°lise', 'n√£o faz analise', 'incipiente', 'n√£o faz an√°lise']):
            return set(['Outras Ferramentas'])
        
        # 1. Primeiro busca pelos padr√µes exatos do mapeamento
        for padrao, categoria in mapeamento_ferramentas.items():
            if padrao.lower() in texto:
                categorias.add(categoria)
        
        # 2. Busca por palavras-chave para categorizar automaticamente
        palavras_chave = {
            'Planilhas': ['planilha', 'excel', 'google sheets', 'calc', 'sheet'],
            'Sistemas SUS': ['sistema', 'tabwin', 'tabnet', 'sus', 'sinan', 'siscan', 'sivep', 
                           'sisvan', 'sim', 'sinasc', 'gal', 'sia', 'sih', 'datasus', 'e-sus'],
            'Pain√©is BI': ['painel', 'bi', 'business intelligence', 'qlik', 'power bi', 'looker', 
                          'oracle', 'tableau', 'dashboard', 'pain√©is'],
            'Apresenta√ß√µes': ['apresenta√ß√£o', 'powerpoint', 'google slides', 'slide', 'ppt']
        }
        
        for categoria, palavras in palavras_chave.items():
            for palavra in palavras:
                if palavra in texto:
                    categorias.add(categoria)
                    break
        
        # Se n√£o encontrou nenhuma categoria padr√£o, classifica como "Outras Ferramentas"
        if len(categorias) == 0:
            categorias.add('Outras Ferramentas')
        
        return categorias
    
    # Criar colunas dummy para cada categoria
    categorias = ['Planilhas', 'Sistemas SUS', 'Pain√©is BI', 'Apresenta√ß√µes', 'Outras Ferramentas']
    
    for categoria in categorias:
        coluna_nome = f"ferramenta_{categoria.lower().replace(' ', '_').replace('√£', 'a').replace('√ß', 'c').replace('√©', 'e')}"
        df[coluna_nome] = df['ferramentas_analise'].apply(
            lambda x: 1 if categoria in categorizar_ferramentas(x) else 0
        )
    
    # Debug: mostrar distribui√ß√£o
    print("Distribui√ß√£o das ferramentas:")
    for categoria in categorias:
        coluna = f"ferramenta_{categoria.lower().replace(' ', '_').replace('√£', 'a').replace('√ß', 'c').replace('√©', 'e')}"
        print(f"{categoria}: {df[coluna].sum()}")
    
    # Calcular quantidade de ferramentas usadas (excluindo "Outras Ferramentas")
    colunas_ferramentas_principais = [f"ferramenta_{cat.lower().replace(' ', '_').replace('√£', 'a').replace('√ß', 'c').replace('√©', 'e')}" 
                                     for cat in ['Planilhas', 'Sistemas SUS', 'Pain√©is BI', 'Apresenta√ß√µes']]
    
    df['qtd_ferramentas'] = df[colunas_ferramentas_principais].sum(axis=1)
    
    # Categorizar por quantidade
    conditions = [
        df['qtd_ferramentas'] == 0,
        df['qtd_ferramentas'] == 1,
        df['qtd_ferramentas'] == 2,
        df['qtd_ferramentas'] >= 3
    ]
    
    choices = ['Nenhuma', '1 ferramenta', '2 ferramentas', '3+ ferramentas']
    
    df['categoria_ferramentas'] = np.select(conditions, choices, default='Nenhuma')
    
    '''
    print(f"\nPessoas sem ferramentas principais: {(df['qtd_ferramentas'] == 0).sum()}")
    print(f"Pessoas com 1 ferramenta principal: {(df['qtd_ferramentas'] == 1).sum()}")
    print(f"Pessoas com 2 ferramentas principais: {(df['qtd_ferramentas'] == 2).sum()}")
    print(f"Pessoas com 3+ ferramentas principais: {(df['qtd_ferramentas'] >= 3).sum()}")
    print(f"Pessoas com outras ferramentas: {df['ferramenta_outras_ferramentas'].sum()}")
    '''

    return df

def transformar_categoricos_grandes(df: pd.DataFrame) -> pd.DataFrame:
    """
    Transforma as colunas em valores num√©ricos e categorias ordenados
    """
    
    # Mapeamento para valores num√©ricos (ponto m√©dio dos intervalos)
    mapeamento_numerico = {
        '1 a 10': 5,
        '11 a 15': 13, 
        '16 a 20': 18,
        '21 ou mais': 25,
        'Nenhum': 0,
        'N√£o sei informar': None,
        '': None
    }
    
    
    # Aplicar mapeamento √†s colunas espec√≠ficas
    colunas_perifericos = [
        'estacoes_trabalho_boas'
    
    ]

    
    for coluna in colunas_perifericos:
        if coluna not in df.columns:
            continue
            
        # 1. Criar vers√£o num√©rica
        df[f'{coluna}_num'] = df[coluna].map(mapeamento_numerico)
        
        # 2. Substituir a coluna original pela vers√£o ordenada
        ordem_categorias = ['Nenhum', '1 a 10', '11 a 15', '16 a 20', '21 ou mais']
        df[coluna] = pd.Categorical(
            df[coluna], 
            categories=ordem_categorias, 
            ordered=True
        )
        
        # 3. Criar categorias simplificadas
        conditions = [
            df[coluna].isin(['1 a 10', 'Nenhum']),
            df[coluna] == '11 a 15',
            df[coluna] == '16 a 20', 
            df[coluna] == '21 ou mais',
            df[coluna].isin(['N√£o sei informar', 'N√£o se aplica'])

        ]
        
        choices = ['Baixa', 'M√©dia', 'Alta', 'Muito Alta', 'N√£o informado']
        df[f'{coluna}_cat_simples'] = np.select(conditions, choices, default='N√£o informado')

    return df

def transformar_categoricos_pequenos(df: pd.DataFrame) -> pd.DataFrame:
    """
    Transforma as colunas em valores num√©ricos e categorias ordenados
    """
    
    # Mapeamento para valores num√©ricos (ponto m√©dio dos intervalos)
    mapeamento_numerico = {
        'Nenhum': 0,
        '1': 1,
        '2': 2,
        '3 a 5': 4,  # ponto m√©dio
        '6 ou mais': 6,
        'N√£o sei informar': None,
        'N√£o se aplica': None,
        '': None
    }
    
    colunas_perifericos = [
        'webcams_disponiveis',
        'microfones_disponiveis', 
        'fones_disponiveis',
        'caixas_som_disponiveis',
        'notebooks_com_camera',
        'notebooks_com_caixa_som', 
        'notebooks_com_microfone',

        'notebooks_boas',
        'computadores_problema',

        'televisores',
        'projetores'
    
    ]
    
    for coluna in colunas_perifericos:
        if coluna not in df.columns:
            print(f"‚ö†Ô∏è Coluna {coluna} n√£o encontrada")
            continue
            
        print(f"\nüîç Analisando {coluna}:")
        print(f"Valores √∫nicos antes: {df[coluna].unique()}")
        print(f"Contagem de valores:\n{df[coluna].value_counts()}")
        
        # 1. Criar vers√£o num√©rica
        df[f'{coluna}_num'] = df[coluna].map(mapeamento_numerico)
        
        print(f"Valores num√©ricos criados:")
        print(f"M√≠nimo: {df[f'{coluna}_num'].min()}")
        print(f"M√°ximo: {df[f'{coluna}_num'].max()}")
        print(f"M√©dia: {df[f'{coluna}_num'].mean()}")
        print(f"Contagem de NaNs: {df[f'{coluna}_num'].isna().sum()}")
        
        # 2. Restante do seu c√≥digo...
        ordem_categorias = ['Nenhum', '1', '2', '3 a 5', '6 ou mais', 'N√£o sei informar', 'N√£o se aplica']
        df[coluna] = pd.Categorical(df[coluna], categories=ordem_categorias, ordered=True)
        
        conditions = [
            df[coluna].isin(['Nenhum', '1']),
            df[coluna] == '2',
            df[coluna] == '3 a 5', 
            df[coluna] == '6 ou mais',
            df[coluna].isin(['N√£o sei informar', 'N√£o se aplica'])
        ]
        
        choices = ['Baixa', 'M√©dia', 'Alta', 'Muito Alta', 'N√£o informado']
        df[f'{coluna}_cat_simples'] = np.select(conditions, choices, default='N√£o informado')

    return df


def transformar_escala_ordenada(df: pd.DataFrame, coluna: str, ordem_categorias: list) -> pd.DataFrame:
    """
    Fun√ß√£o auxiliar para transformar qualquer coluna em categ√≥rica ordenada
    """
    if coluna not in df.columns:
        return df
        
    # Converter para categ√≥rica ordenada
    df[coluna] = pd.Categorical(
        df[coluna], 
        categories=ordem_categorias, 
        ordered=True
    )
    
    return df

def transformar_escalas_zero_dez(df: pd.DataFrame) -> pd.DataFrame:
    """
    Aplica transforma√ß√£o ordenada a todas as colunas de escala 0-10
    """
    mapeamento_numerico = {
        '0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5,
        '6': 6, '7': 7, '8': 8, '9': 9, '10': 10,
        'N√£o sei informar': None, 'N√£o se aplica': None,
    }
    
    # Definir a ordem natural para escala 0-10
    ordem_escala = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']
    
    # Colunas que s√£o escalas 0-10
    colunas_escala = ['qualidade_internet']
    
    for coluna in colunas_escala:
        if coluna not in df.columns:
            continue
            
        # 1. Criar vers√£o num√©rica
        df[f'{coluna}_num'] = df[coluna].map(mapeamento_numerico)
        
        # 2. Aplicar transforma√ß√£o ordenada usando a fun√ß√£o auxiliar
        df = transformar_escala_ordenada(df, coluna, ordem_escala)
        
        # 3. Criar categorias simplificadas
        conditions = [
            df[coluna].isin(['0', '1', '2', '3']),
            df[coluna].isin(['4', '5', '6']),
            df[coluna].isin(['7', '8']),
            df[coluna].isin(['9', '10']),
            df[coluna].isin(['N√£o sei informar', 'N√£o se aplica'])
        ]
        
        choices = ['Baixa (0-3)', 'M√©dia (4-6)', 'Alta (7-8)', 'Muito Alta (9-10)', 'N√£o informado']
        df[f'{coluna}_cat_simples'] = np.select(conditions, choices, default='N√£o informado')
    
    return df

def transformar_escala_ordenada(df: pd.DataFrame, coluna: str, ordem_categorias: list) -> pd.DataFrame:
    """
    Fun√ß√£o auxiliar para transformar qualquer coluna em categ√≥rica ordenada
    """
    if coluna not in df.columns:
        return df
        
    # Converter para categ√≥rica ordenada
    df[coluna] = pd.Categorical(
        df[coluna], 
        categories=ordem_categorias, 
        ordered=True
    )
    
    return df

def transformar_escalas_zero_dez(df: pd.DataFrame) -> pd.DataFrame:
    """
    Aplica transforma√ß√£o ordenada a todas as colunas de escala 0-10
    """
    mapeamento_numerico = {
        '0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5,
        '6': 6, '7': 7, '8': 8, '9': 9, '10': 10,
        'N√£o sei informar': None, 'N√£o se aplica': None,
    }
    
    # Definir a ordem natural para escala 0-10
    ordem_escala = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']
    
    # Colunas que s√£o escalas 0-10
    colunas_escala = ['qualidade_internet']
    
    for coluna in colunas_escala:
        if coluna not in df.columns:
            continue
            
        # 1. Criar vers√£o num√©rica
        df[f'{coluna}_num'] = df[coluna].map(mapeamento_numerico)
        
        # 2. Aplicar transforma√ß√£o ordenada usando a fun√ß√£o auxiliar
        df = transformar_escala_ordenada(df, coluna, ordem_escala)
        
        # 3. Criar categorias simplificadas
        conditions = [
            df[coluna].isin(['0', '1', '2', '3']),
            df[coluna].isin(['4', '5', '6']),
            df[coluna].isin(['7', '8']),
            df[coluna].isin(['9', '10']),
            df[coluna].isin(['N√£o sei informar', 'N√£o se aplica'])
        ]
        
        choices = ['Baixa (0-3)', 'M√©dia (4-6)', 'Alta (7-8)', 'Muito Alta (9-10)', 'N√£o informado']
        df[f'{coluna}_cat_simples'] = np.select(conditions, choices, default='N√£o informado')
    
    return df

def transformar_escalas_zero_cinco(df: pd.DataFrame) -> pd.DataFrame:
    """
    Aplica transforma√ß√£o ordenada a todas as colunas de escala 1-5
    """
    mapeamento_numerico = {
        '1': 1, '2': 2, '3': 3, '4': 4, '5': 5,
        'N√£o sei informar': None
    }
    
    # Definir a ordem natural para escala 1-5
    ordem_escala = ['1', '2', '3', '4', '5']
    
    # Colunas que s√£o escalas 1-5
    colunas_escala = ['competencia_tecnica_equipe']
    
    for coluna in colunas_escala:
        if coluna not in df.columns:
            continue
            
        # 1. Criar vers√£o num√©rica
        df[f'{coluna}_num'] = df[coluna].map(mapeamento_numerico)
        
        # 2. Aplicar transforma√ß√£o ordenada usando a fun√ß√£o auxiliar
        df = transformar_escala_ordenada(df, coluna, ordem_escala)
        
        # 3. Criar categorias simplificadas
        conditions = [
            df[coluna].isin(['1', '2']),
            df[coluna] == '3',
            df[coluna].isin(['4', '5']),
            df[coluna] == 'N√£o sei informar'
        ]
        
        choices = ['Baixa (1-2)', 'M√©dia (3)', 'Alta (4-5)', 'N√£o informado']
        df[f'{coluna}_cat_simples'] = np.select(conditions, choices, default='N√£o informado')
    
    return df

def tratar_sistemas_e_qualidade(df: pd.DataFrame) -> pd.DataFrame:
    """
    Trata as colunas Q25 (sistemas usados) e Q26 (qualidade dos dados).
    Cria colunas bin√°rias de uso e avalia√ß√£o por sistema.
    Detecta inconsist√™ncias entre uso e avalia√ß√£o.
    """

    # Lista de sistemas poss√≠veis (baseado nas colunas de qualidade)
    sistemas = [
        'SINASC', 'Vida+', 'E-SUS AB/SISAB', 'SINAN', 'GAL',
        'SIA-SUS', 'SIH-SUS', 'SIM', 'Sivep-Gripe', 'E-SUS Notifica', 'Sisvan'
    ]

    # Normalizar a coluna de sistemas usados
    df['sistemas_informacao_utilizados'] = df['sistemas_informacao_utilizados'].fillna('').str.strip()

    # Criar colunas bin√°rias de uso
    for sistema in sistemas:
        col_uso = f'usou_{sistema.lower().replace("-", "_").replace("+", "plus").replace(" ", "_")}'
        df[col_uso] = df['sistemas_informacao_utilizados'].str.contains(sistema, case=False, na=False).astype(int)

    # Criar colunas bin√°rias de avalia√ß√£o (se avaliou, o valor n√£o √© vazio ou "N√£o se aplica")
    for sistema in sistemas:
        col_qualidade = f'qualidade_{sistema.lower().replace("-", "_").replace("+", "plus").replace(" ", "_")}'
        col_avaliou = f'avaliou_{sistema.lower().replace("-", "_").replace("+", "plus").replace(" ", "_")}'

        if col_qualidade in df.columns:
            df[col_avaliou] = df[col_qualidade].notna() & (~df[col_qualidade].isin(['', 'N√£o se aplica'])).astype(int)
        else:
            df[col_avaliou] = 0  # Se n√£o existe coluna de qualidade, n√£o avaliou

    # Detectar inconsist√™ncias
    df['sistemas_inconsistentes'] = 0
    for sistema in sistemas:
        col_uso = f'usou_{sistema.lower().replace("-", "_").replace("+", "plus").replace(" ", "_")}'
        col_avaliou = f'avaliou_{sistema.lower().replace("-", "_").replace("+", "plus").replace(" ", "_")}'

        # Inconsist√™ncia: avaliou mas n√£o usou
        inconsistencia = (df[col_avaliou] == 1) & (df[col_uso] == 0)
        df.loc[inconsistencia, 'sistemas_inconsistentes'] += 1

    # Criar contadores
    df['total_sistemas_usados'] = df[[f'usou_{s.lower().replace("-", "_").replace("+", "plus").replace(" ", "_")}' for s in sistemas]].sum(axis=1)
    df['total_sistemas_avaliados'] = df[[f'avaliou_{s.lower().replace("-", "_").replace("+", "plus").replace(" ", "_")}' for s in sistemas]].sum(axis=1)

    return df

def criar_resumo_sistemas(df: pd.DataFrame) -> pd.DataFrame:
    """
    Cria uma tabela resumo com uso e qualidade m√©dia por sistema.
    """

    sistemas = [
        'SINASC', 'Vida+', 'E-SUS AB/SISAB', 'SINAN', 'GAL', 'SIA-SUS', 'SIH-SUS', 'SIM', 'Sivep-Gripe', 'E-SUS Notifica', 'Sisvan'
    ]

    # Mapeamento correto de sistema -> nomes reais das colunas
    col_map = {
        'SINASC': ('usou_sinasc', 'qualidade_sinasc'),
        'Vida+': ('usou_vidaplus', 'qualidade_vida_plus'),
        'E-SUS AB/SISAB': ('usou_e_sus_ab/sisab', 'qualidade_esus_sisab'),
        'SINAN': ('usou_sinan', 'qualidade_sinan'),
        'GAL': ('usou_gal', 'qualidade_gal'),
        'SIA-SUS': ('usou_sia_sus', 'qualidade_sia_sus'),
        'SIH-SUS': ('usou_sih_sus', 'qualidade_sih_sus'),
        'SIM': ('usou_sim', 'qualidade_sim'),
        'Sivep-Gripe': ('usou_sivep_gripe', 'qualidade_sivep_gripe'),
        'E-SUS Notifica': ('usou_e_sus_notifica', 'qualidade_esus_notifica'),
        'Sisvan': ('usou_sisvan', 'qualidade_sisvan')
    }

    qualidade_map = {
        'Muito Ruim': 1,
        'Ruim': 2, 
        'Bom': 3,
        'Muito bom': 4,
        'Excelente': 5
    }

    resumo = []
    for sistema in sistemas:
        col_uso, col_qualidade = col_map[sistema]
        
        uso = df[col_uso].sum()
        qualidades = df[col_qualidade].dropna().map(qualidade_map)
        
        if len(qualidades) > 0:
            qualidade_media = qualidades.mean()
        else:
            qualidade_media = None
        
        resumo.append({
            'sistema': sistema,
            'uso': uso,
            'qualidade_media': qualidade_media
        })
    
    resumo_df = pd.DataFrame(resumo)
    resumo_df = resumo_df[resumo_df['uso'] > 0]  # s√≥ quem foi usado
    return resumo_df

def criar_resumo_metas(df: pd.DataFrame) -> pd.DataFrame:
    """
    Cria uma tabela resumo com metas distritais.
    """

    distritos = [
        "Brotas",
        "Cajazeiras",
        "Boca do Rio",
        "Itapu√£",
        "S√£o Caetano/Val√©ria",
        "Barra/Rio Vermelho",
        "Cabula/Beir√∫",
        "Sub√∫rbio Ferrovi√°rio",
        "Pau da Lima",
        "Liberdade",
        "Itapagipe",
        "Centro Hist√≥rico"
    ]

    metas = {
        'Brotas': 50,
        'Cajazeiras': 40,
        'Boca do Rio': 32,
        'Itapu√£': 43,
        'S√£o Caetano/Val√©ria': 41,
        'Barra/Rio Vermelho': 34,
        'Cabula/Beir√∫': 39,
        'Sub√∫rbio Ferrovi√°rio': 58,
        'Pau da Lima': 47,
        'Liberdade': 30,
        'Itapagipe': 42,
        'Centro Hist√≥rico': 45
    }

    resumo = []
    for distrito in distritos:
        meta = metas.get(distrito, None)
        resumo.append({
            'distrito': distrito,
            'meta_distrital': meta
        })
    
    resumo_df = pd.DataFrame(resumo)
    return resumo_df

def criar_tabelas_dimensao():
    # -------------------------------------------------------------------
    # CRIA√á√ÉO DAS TABELAS DE DIMENS√ÉO
    # -------------------------------------------------------------------
    logger.info("Criando tabelas de dimens√£o...")

    with open("tabelas_dimensionamento.json", "r", encoding="utf-8") as f:
        dims = json.load(f)["dimension_tables"]

    abas = {}
    for nome, conteudo in dims.items():
        df = pd.DataFrame(conteudo["data"])
        aba_nome = f"{nome}"
        abas[aba_nome] = df

    return abas


# FUN√á√ïES para INDICADORES ‚Äì PONTUA√á√ÉO POR DIMENS√ÉO

def _pontuar_pessoas(df: pd.DataFrame) -> pd.Series:
    """
    0-100 baseado em:
    - competencia_tecnica_equipe (1-5)
    - participa_qualificacoes
    - cultura_uso_dados
    - qtd_ferramentas (0-4+)
    """
    logger = logging.getLogger("ETL.ip_sala_situacao.pessoas")

    # ---- valores brutos ----
    comp_raw = pd.to_numeric(df['competencia_tecnica_equipe_num'], errors='coerce').fillna(1)
    comp = comp_raw / 5                                    # 0-1
    qual = df['participa_qualificacoes'].map({
        'Sim, regularmente (ao menos uma vez por ano)': 1,
        'Sim, mas esporadicamente': 0.5,
        'N√£o': 0
    }).fillna(0)
    cult = df['cultura_uso_dados'].map({
        'Sim, a an√°lise de dados √© central em nossas reuni√µes e planejamentos.': 1,
        'Em partes, usamos dados, mas as decis√µes ainda s√£o muito baseadas na experi√™ncia.': 0.5,
        'N√£o, os dados s√£o vistos mais como uma obriga√ß√£o de preenchimento do que como uma ferramenta de gest√£o.': 0
    }).fillna(0)
    ferr = np.minimum(df['qtd_ferramentas'].fillna(0), 4) / 4   # 0-1

    # ---- log de exemplo (primeira linha) ----
    if len(df) > 0:
        logger.info(f"Exemplo linha 0 -> comp: {comp.iloc[0]:.2f}, qual: {qual.iloc[0]:.2f}, "
                    f"cult: {cult.iloc[0]:.2f}, ferr: {ferr.iloc[0]:.2f}")

    # ---- score final 0-100 (sem duplicar *100) ----
    score = (
        comp * 40 +
        qual * 25 +
        cult * 25 +
        ferr * 10
    ) * 1
    return score.clip(0, 100)

def _pontuar_infraestrutura(df: pd.DataFrame) -> pd.Series:
    logger = logging.getLogger("ETL.ip_sala_situacao.infra")

    est = df['estacoes_trabalho_boas_num'].fillna(0) / 25
    note = df['notebooks_boas_num'].fillna(0) / 6
    net_ok = (df['internet_estavel'] == 'Sim').astype(int)
    net_not = pd.to_numeric(df['qualidade_internet_num'], errors='coerce').fillna(0) / 10
    sala = (df['sala_situacao'] == 'Sim, possui uma sala adequada').astype(int)
    cabo = (df['cabos_adaptadores'] == 'Sim, para todos os equipamentos').astype(int)

    if len(df) > 0:
        logger.info(f"Exemplo linha 0 -> est: {est.iloc[0]:.2f}, note: {note.iloc[0]:.2f}, "
                    f"net_ok: {net_ok.iloc[0]:.2f}, net_not: {net_not.iloc[0]:.2f}, "
                    f"sala: {sala.iloc[0]:.2f}, cabo: {cabo.iloc[0]:.2f}")

    score = (
        est * 30 +
        note * 15 +
        net_ok * 20 + net_not * 10 +
        sala * 20 +
        cabo * 5
    )  # <-- removido *100
    return score.clip(0, 100)

def _pontuar_processos(df: pd.DataFrame) -> pd.Series:
    logger = logging.getLogger("ETL.ip_sala_situacao.processos")

    # ---- etapas normalizadas 0-1 ----
    ind_def     = (df['indicadores_definidos']        == 'Sim').astype(int)
    dados_meta  = df['dados_subsidiam_metas'].map({'Sim': 1, 'Parcialmente': 0.5, 'N√£o': 0, 'N√£o sei informar': 0})
    meta_dados  = df['metas_base_dados'].map({'Sim': 1, 'Parcialmente': 0.5, 'N√£o': 0, 'N√£o sei informar': 0})
    fluxos      = (df['fluxos_formalizados']         == 'Sim').astype(int)
    rotina      = (df['rotina_validacao']            == 'Sim').astype(int)
    paineis     = df['paineis_tomada_decisao'].map({'Sim': 1, 'Parcialmente': 0.5, 'N√£o': 0, 'N√£o sei informar': 0})

    # ---- log amostral (5 primeiras) ----
    for i in range(min(5, len(df))):
        logger.info(f"idx {i} -> ind_def:{ind_def.iloc[i]:.2f} dados_meta:{dados_meta.iloc[i]:.2f} "
                    f"meta_dados:{meta_dados.iloc[i]:.2f} fluxos:{fluxos.iloc[i]:.2f} "
                    f"rotina:{rotina.iloc[i]:.2f} paineis:{paineis.iloc[i]:.2f}")

    score = (
        ind_def   * 20 +
        dados_meta * 15 +
        meta_dados * 15 +
        fluxos    * 15 +
        rotina    * 20 +
        paineis   * 15
    )  # j√° 0-100
    logger.info(f"ESTAT√çSTICA processos -> min:{score.min():.1f} | m√©dia:{score.mean():.1f} | max:{score.max():.1f}")
    return score.clip(0, 100)

def _pontuar_seguranca(df: pd.DataFrame) -> pd.Series:
    logger = logging.getLogger("ETL.ip_sala_situacao.seguranca")

    # ---- etapas normalizadas 0-1 ----
    lgpd        = df['conhecimento_lgpd'].map({'Sim': 1, 'Tenho uma no√ß√£o, mas n√£o conhe√ßo em detalhes': 0.5, 'N√£o': 0})
    treino      = df['treinamento_lgpd'].map({'Sim': 1, 'Apenas orienta√ß√µes informais': 0.5, 'N√£o': 0})
    acesso      = df['acesso_individualizado'].map({'Sim': 1, 'Em parte (alguns sistemas sim, outros n√£o)': 0.5, 'N√£o, os acessos s√£o compartilhados': 0})
    backup      = (df['protocolos_backup'] == 'Sim').astype(int)

    # ---- log amostral (5 primeiras) ----
    for i in range(min(5, len(df))):
        logger.info(f"idx {i} -> lgpd:{lgpd.iloc[i]:.2f} treino:{treino.iloc[i]:.2f} "
                    f"acesso:{acesso.iloc[i]:.2f} backup:{backup.iloc[i]:.2f}")

    score = (
        lgpd   * 30 +
        treino * 25 +
        acesso * 25 +
        backup * 20
    )  # j√° 0-100
    logger.info(f"ESTAT√çSTICA seguranca -> min:{score.min():.1f} | m√©dia:{score.mean():.1f} | max:{score.max():.1f}")
    return score.clip(0, 100)

# FUN√á√ÉO PRINCIPAL ‚Äì ADICIONA O √çNDICE
def adicionar_ip_sala_situacao(df: pd.DataFrame) -> pd.DataFrame:
    logger.info("Calculando IP-SalaSit...")
    df = df.copy()

    # garantir que colunas num√©ricas j√° existam
    num_cols = ['competencia_tecnica_equipe_num', 'estacoes_trabalho_boas_num',
                'notebooks_boas_num', 'qualidade_internet_num', 'qtd_ferramentas']
    for c in num_cols:
        if c not in df.columns:
            logger.warning(f"Coluna {c} n√£o encontrada ‚Äì preenchendo com 0")
            df[c] = 0

    df['ip_pessoas'] = _pontuar_pessoas(df)
    df['ip_infra'] = _pontuar_infraestrutura(df)
    df['ip_processos'] = _pontuar_processos(df)
    df['ip_seguranca'] = _pontuar_seguranca(df)

    df['ip_sala_situacao'] = (
        0.30 * df['ip_pessoas'] +
        0.30 * df['ip_infra'] +
        0.25 * df['ip_processos'] +
        0.15 * df['ip_seguranca']
    ).round(2)

    logger.info("IP-SalaSit calculado com sucesso.")
    return df

# -------------------------------------------------------------------
# # TRANSFORM ‚Äì APLICA TRANSFORMA√á√ïES NOS DADOS
# -------------------------------------------------------------------
def transform(df: pd.DataFrame) -> pd.DataFrame:
    logger.info("Iniciando transforma√ß√µes...")
    
    df = rename_columns(df)
    df = normalizar_area_atuacao(df)
    df = transformar_atuacao_info(df)
    df = transformar_ferramentas_analise(df)
    df = transformar_categoricos_grandes(df)
    df = transformar_categoricos_pequenos(df)
    df = transformar_escalas_zero_dez(df)
    df = transformar_escalas_zero_cinco(df)
    df = tratar_sistemas_e_qualidade(df)
    df = adicionar_ip_sala_situacao(df)

    logger.info("Transforma√ß√£o conclu√≠da.")
    return df

# -------------------------------------------------------------------
# LOAD ‚Äì CRIA ABA E ESCREVE DADOS NA MESMA PLANILHA
# -------------------------------------------------------------------
def load_to_sheet(client, sheet_id: str, df: pd.DataFrame, new_tab: str = "DadosEtl"):
    logger.info(f"Criando aba '{new_tab}' na planilha...")

    sh = client.open_by_key(sheet_id)

    try:
        existing = sh.worksheet(new_tab)
        sh.del_worksheet(existing)
        logger.info("Aba existente encontrada ‚Üí removida.")
    except gspread.exceptions.WorksheetNotFound:
        pass

    ws = sh.add_worksheet(title=new_tab, rows=str(len(df) + 5), cols=str(len(df.columns) + 5))

    # Preparar dados
    df_preparado = df.copy()
    
    for col in df_preparado.columns:
        if df_preparado[col].dtype.name == 'category':
            df_preparado[col] = df_preparado[col].astype(str)
    
    df_preparado = df_preparado.fillna('')

    # üî• ENVIAR DADOS UMA √öNICA VEZ
    values = [df_preparado.columns.tolist()] + df_preparado.values.tolist()
    ws.update(values)

    # üî• FORMATAR COMO TABELA COMPLETA
    try:
        # 1. Congelar primeira linha
        ws.freeze(rows=1)
        
        logger.info(f"Aba '{new_tab}' formatada como tabela completa.")
        
    except Exception as e:
        logger.warning(f"N√£o foi poss√≠vel aplicar formata√ß√£o completa: {e}")

    logger.info(f"Aba '{new_tab}' criada com sucesso.")

# -------------------------------------------------------------------
# MAIN
# -------------------------------------------------------------------
def main():
    SHEET_ID = "1GEFCBgoE5ed9yrEjAYe-FbWwXsIfc5G9mU2Gi0Yu_Kw"
    TAB = "BaseBruta"
    NEW_TAB = "DadosEtl"

    df, client = extract(SHEET_ID, TAB)
    df = transform(df)
    
    # üî• USAR load_to_sheet PARA TODAS AS ABAS
    load_to_sheet(client, SHEET_ID, df, NEW_TAB)

    # Criar e carregar resumos usando load_to_sheet
    resumo_df = criar_resumo_sistemas(df)
    load_to_sheet(client, SHEET_ID, resumo_df, "ResumoSistemas")

    resumo_metas_df = criar_resumo_metas(df)
    load_to_sheet(client, SHEET_ID, resumo_metas_df, "ResumoMetas")

    # üî• CARREGAR TABELAS DE DIMENS√ÉO COM load_to_sheet E DELAYS
    try:
        dim_abas = criar_tabelas_dimensao()
        for i, (aba_nome, dim_df) in enumerate(dim_abas.items()):
            load_to_sheet(client, SHEET_ID, dim_df, aba_nome)
            
            # Delay entre cada tabela de dimens√£o (exceto a √∫ltima)
            if i < len(dim_abas) - 1:
                logger.info(f"Delay aplicado ap√≥s criar {aba_nome}")
                
    except Exception as e:
        logger.error(f"Erro ao criar abas de dimens√£o: {e}")
    
    logger.info("ETL COMPLETO! Todas as abas formatadas como tabelas.")


if __name__ == "__main__":
    main()